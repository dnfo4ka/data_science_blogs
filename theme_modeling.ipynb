{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "theme modeling",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnfo4ka/data_science_blogs/blob/master/theme_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N20j8C8tL5EB"
      },
      "source": [
        "# Семинар: Тематическое моделирование"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhJ3oUImoRuU"
      },
      "source": [
        "## Вводная часть"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp01H9hSLzFx"
      },
      "source": [
        "***Тематическое моделирование*** — подраздел машинного обучения, посвященный извлечению абстрактных «тем» из набора «документов». С помощью тематического моделирования можно определить, к каким темам относится каждый из документов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk17IUgaRJlC"
      },
      "source": [
        "#### **Как люди ищут информацию?**\n",
        "\n",
        "- рубликатор в библиотеке или на сайте\n",
        "- оглавление и глоссарий в книге или научной работе\n",
        "- изобретение современности - поисковик"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFT11EosTaRu"
      },
      "source": [
        "#### **Проблема эффективного поиска**\n",
        "Однако проблема эффективного поиска сохраняется.\n",
        "\n",
        "В классическом поиске, когда мы ищем по ключевым словам мы исходим из того, что:\n",
        "\n",
        "1. Точно должны знать что мы ищем.\n",
        "2. Должны предполагать, что существует правильный ответ.\n",
        "\n",
        "Что если нам нужно узнать где передний край науки по нужной мне области? Или нужно быстро разобраться в смежной области.\n",
        "\n",
        "Но мы еще на владеем терминологией и не понимаем что важно, что неважно, по каким ключевым словам следует искать информацию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r76AHvORDblK"
      },
      "source": [
        "**Цель** - выполение эффективного разведочного информационного поиска в рамках определенной предметной области.\n",
        "\n",
        "**Идея** - давайте построим топологию областей знаний."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uTD0pD8QmSE"
      },
      "source": [
        "#### **Примеры визуализаций топологий областей знаний:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbNo9YXBDblL"
      },
      "source": [
        "<img src=\"https://carrotsearch.com/assets/carrotsearch/features/foamtree/non-rectangular-layout-0720.jpg\" width=\"500\"/>\n",
        "\n",
        "---\n",
        "https://carrotsearch.com/foamtree/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ5XVqEHDblL"
      },
      "source": [
        "<img src=\"https://pbs.twimg.com/media/DY_tjS0WsAADhmT?format=png\" width=\"500\"/>\n",
        "\n",
        "---\n",
        "https://dl.acm.org/doi/book/10.5555/1995300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNIuJVIrHQrk"
      },
      "source": [
        "<img src=\"https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0004803.g005&type=large\" width=\"500\"/>\n",
        "\n",
        "---\n",
        "https://doi.org/10.1371/journal.pone.0004803.g005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLsiA6vaITxO"
      },
      "source": [
        "<img src=\"https://images.squarespace-cdn.com/content/v1/5edff03d09fb5c4e902ff773/1599834383522-FBMN3YPE5CCOKKOLWUHZ/ke17ZwdGBToddI8pDm48kGecZjL07O2JiRRvz-fC_KdZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpz1BFr50UANsCziYGpjNa_6MEhfCL4YxGEARaKTxXTEd4uO9Wa62Az3Po02OVjPqB0/map-of-the-complexity-sciences-tcs.jpg\" width=\"500\"/>\n",
        "\n",
        "---\n",
        "https://www.theoryculturesociety.org/brian-castellani-on-the-complexity-sciences/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GEFE3azDblM"
      },
      "source": [
        "#### **Сценарий поиска**\n",
        "\n",
        "При наличии такой топологии **сценарий поиска** будет следующий:\n",
        "1. имея любой текст под рукой, в любом приложении,\n",
        "2. хотим получить картину содержащихся в нём тем-подтем,\n",
        "3. и «дорожную карту» предметной области в целом\n",
        "\n",
        "**Поисковый запрос:**\n",
        "- документ любой длины или даже коллекция документов\n",
        "\n",
        "**Цели поиска:**\n",
        "- к каким темам относится мой запрос?\n",
        "- что ещё известно по этим темам?\n",
        "- какова тематическая структура этой предметной области?\n",
        "- что ещё есть понятного, обзорного, важного, свежего?\n",
        "\n",
        "---\n",
        "http://www.machinelearning.ru/wiki/images/7/78/Voron-2015-06-19-school-VII.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGS_m6bkDblM"
      },
      "source": [
        "#### **Как искать?**\n",
        "\n",
        "Мы умеем искать по словам документы, это называется инвертированным индексом. А если у нас поиск по смыслу, по тематике, то что мы должны сделать? Мы должны понять, данный документ запроса — он на какие темы?\n",
        "\n",
        "Документ может быть очень длинным, но число тем в нем может быть не очень большим. Если мы научимся представлять любой документ в виде набора тем — может быть, с весами, определяющими, насколько каждая тема в нем представлена, — то дальше мы можем воспользоваться тем же методом, что при при обычном поиске по словам с помощью инвертированного индекса.\n",
        "\n",
        "У нас как любой запрос, так и любой документ теперь представлены не словами, а темами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z30scdPM9zr"
      },
      "source": [
        "#### **Что такое «тема»?**\n",
        "\n",
        "\n",
        "Тема — специальная терминология предметной области.\n",
        "\n",
        "Тема — набор часто совместно встречающихся терминов.\n",
        "\n",
        "Тема — семантически однородный кластер текстов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX3gUrzlPJLt"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/%D0%A2%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C.png/2880px-%D0%A2%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C.png\" width=\"800\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFArHWrNQ4ev"
      },
      "source": [
        "Более формально:\n",
        "\n",
        "*тема* — условное распределение на множестве терминов,\n",
        "\n",
        "*φ = p(w|t)* — вероятность термина w в теме t;\n",
        "\n",
        "*тематический профиль документа* — условное распределение\n",
        "\n",
        "*θ = p(t|d)* — вероятность темы t в документе d.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gd8DYKrY1Z3"
      },
      "source": [
        "Когда автор писал термин w в документ d, он думал о теме t, и мы хотели бы догадаться, о какой именно.\n",
        "\n",
        "Тематическая модель выявляет латентные темы по\n",
        "наблюдаемым распределениям слов p(w|d) в документах.\n",
        "\n",
        "---\n",
        "http://www.machinelearning.ru/wiki/images/e/e6/Voron-ML-TopicModeling-slides.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX7oO2dbae7G"
      },
      "source": [
        "Это задача стохастического матричного разложения:\n",
        "\n",
        "<img src=\"https://i.ibb.co/g4Mdsfc/Screenshot-2020-05-06-at-17-36-05.png\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8MLIX4cuc2b"
      },
      "source": [
        "После выявления списка тем мы можем упорядочить их таким образом, чтобы близкие по смыслу темы оказались рядом:\n",
        "\n",
        "<img src=\"https://i.ibb.co/QMthMcS/Screenshot-2020-05-06-at-23-41-55.png\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POgZgCxHodjm"
      },
      "source": [
        "## Практика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UL9YqLNeNvv"
      },
      "source": [
        "Версия только с кодом: https://colab.research.google.com/drive/1cZmkRqCKzQBvjL0OCgmC7_0uvyh35-86#scrollTo=A6dvFqfAkN0v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lglZUOVQ6rd"
      },
      "source": [
        "### **BigARTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8skHmHPwJG-H"
      },
      "source": [
        "<img src=\"https://github.com/bigartm/visartm/blob/master/static/img/BigARTM-logo-big.png?raw=true\" width=\"200\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5RlTPI1NAtJ"
      },
      "source": [
        "Обобщение тематических моделей с помощью аддитивной регуляризации (ARTM):\n",
        "\n",
        "https://link.springer.com/article/10.1007/s10994-014-5476-6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1wMM2rcNOFV"
      },
      "source": [
        "Проект BigARTM, реализующий идеи ARTM:\n",
        "https://github.com/bigartm/bigartm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6DnxhhO1Qhj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "25d9e1bb-9135-49fe-c1fd-88cc24795492"
      },
      "source": [
        "!pip install bigartm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bigartm in /usr/local/lib/python3.6/dist-packages (0.9.2)\n",
            "Requirement already satisfied: protobuf>=3.0 in /usr/local/lib/python3.6/dist-packages (from bigartm) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from bigartm) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bigartm) (1.18.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from bigartm) (1.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0->bigartm) (46.1.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0->bigartm) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->bigartm) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->bigartm) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO3yOQo9kN0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f8e1585-f329-43c1-c790-db49fcd38ca9"
      },
      "source": [
        "import artm\n",
        "\n",
        "print(artm.version())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT25eRiABOPX"
      },
      "source": [
        "**All datasets are here:** https://bigartm.readthedocs.io/en/master/tutorials/datasets.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEVF8FztpSKq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "4b627fd4-80df-4911-8207-9e1ebf19a770"
      },
      "source": [
        "!wget https://s3-eu-west-1.amazonaws.com/artm/docword.kos.txt.gz\n",
        "!wget https://s3-eu-west-1.amazonaws.com/artm/vocab.kos.txt\n",
        "!gunzip docword.kos.txt.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-06 21:48:12--  https://s3-eu-west-1.amazonaws.com/artm/docword.kos.txt.gz\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.108.75\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.108.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1053803 (1.0M) [application/x-gzip]\n",
            "Saving to: ‘docword.kos.txt.gz’\n",
            "\n",
            "docword.kos.txt.gz  100%[===================>]   1.00M  1.72MB/s    in 0.6s    \n",
            "\n",
            "2020-05-06 21:48:13 (1.72 MB/s) - ‘docword.kos.txt.gz’ saved [1053803/1053803]\n",
            "\n",
            "--2020-05-06 21:48:14--  https://s3-eu-west-1.amazonaws.com/artm/vocab.kos.txt\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.56.43\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.56.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 55467 (54K) [text/plain]\n",
            "Saving to: ‘vocab.kos.txt’\n",
            "\n",
            "vocab.kos.txt       100%[===================>]  54.17K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-05-06 21:48:14 (563 KB/s) - ‘vocab.kos.txt’ saved [55467/55467]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSVqeS9_kN0e"
      },
      "source": [
        "### 1. Словари и батчи в BigARTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peWENPBqW_lF"
      },
      "source": [
        "# продублируем коллекцию kos с именем my_collection для работы примеров кода по работе с коллекциями\n",
        "\n",
        "!cp vocab.kos.txt vocab.my_collection.txt\n",
        "!cp docword.kos.txt docword.my_collection.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgdOA_LwmB7l"
      },
      "source": [
        "В Python API BigARTM, по аналогии с алгоритмами из scikit-learn, входные данные представлены одним классом BatchVectorizer. Объект этого класса принимает на вход батчи или файлы и подаётся на вход всем методам. В случае, если входные данные не являются батчами, он создаёт их и сохраняет на диск для последующего быстрого использования."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLZ8XzLJkN0f"
      },
      "source": [
        "Прежде, чем приступать непосредственно к моделированию, необходимо привести данные к формату, подходящему для использования библиотекой. Форматы сырых данных, которые можно подавать BigARTM (https://bigartm.readthedocs.io/en/master/tutorials/datasets.html). Перевод же этих данных во внутренний формат библиотеки (пакеты документов, именуемы батчами), можно проделать с помощью создания объекта класса BatchVectorizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsUuO4TPkN0i"
      },
      "source": [
        "Итак, в том случае, если у Вам есть данные в формате UCI (т. е. файлы vocab.my_collection.txt и docword.my_collection.txt), которые лежат в одной директории с исполняемым кодом (в данном случае - с этим ноутбуком), создание батчей можно произвести с помощью следующего кода:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n2PvVCckN0j"
      },
      "source": [
        "batch_vectorizer = artm.BatchVectorizer(data_path='',\n",
        "                                        data_format='bow_uci',\n",
        "                                        collection_name='my_collection',\n",
        "                                        target_folder='my_collection_batches')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j4g8e-EkN0l"
      },
      "source": [
        "Встроенный парсер библиотеки преобразовал Ваши данные в батчи, обернув их в объект класса BatchVectorizer, который является универсальным типом входных данных для всех методов Python API, прочесть о нём можно тут http://bigartm.readthedocs.org/en/master/api_references/python_interface/batches_utils.html. Сами батчи разместились в директории, которую Вы указали как target_folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly1mbQQwkN0q"
      },
      "source": [
        "**Важно**: если Вы один раз проделали операцию по созданию батчей из исходных файлов, то в дальнейшем перезапускать этот процесс не нужно, поскольку для больших коллекций он довольно емкий по времени. Вместо этого достаточно запустить следующий код, который создаст BatchVectorizer на основе существующих батчей (данная операция мгновенная):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_2vKwHIkN0q"
      },
      "source": [
        "batch_vectorizer = artm.BatchVectorizer(data_path='my_collection_batches',\n",
        "                                        data_format='batches')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDR7pkRHkN0t"
      },
      "source": [
        "Следующая цель после создания батчей - создание словаря. Они хранят информацию обо всех уникальных словах в коллекции. Словарь создаётся вне модели, и различными способами (посмотреть их все Вы можете вот тут http://bigartm.readthedocs.org/en/master/api_references/python_interface/dictionary.html).\n",
        "Самый базовый вариант - \"собрать\" словарь по директории с батчами. Это нужно делать один раз в самом начале работы с новой коллекцией следующим образом:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yuCNGQLkN0t"
      },
      "source": [
        "dictionary = artm.Dictionary()\n",
        "dictionary.gather(data_path='my_collection_batches')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6dvFqfAkN0v"
      },
      "source": [
        "В таком варианте слова в словаре (и в дальнейшей матрице $\\Phi$) будут идти в случайном порядке. Если Вам требуется сохранить какой-то порядок, создайте файл вида vocab (см. формат UCI), в котором уникальные слова коллекции будут идти в том порядке, какой Вам более предпочтителен, и запустите следующий код (пусть файл называется vocab.txt и лежит в одной директории с ноутбуком):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QujIBG6MkN0w"
      },
      "source": [
        "dictionary = artm.Dictionary()\n",
        "dictionary.gather(data_path='my_collection_batches',\n",
        "                  vocab_file_path='vocab.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_VnSX_dkN0y"
      },
      "source": [
        "Важно понимать, что в случае использования файла vocab этого библиотека будет работать только с теми словами, которые Вы указали в этом файле, прочие слова батчей будут игнорироваться. Словари содержат много различной полезной информации о коллекции. В них каждому слову соответствует переменная - value. Когда библиотека собирает словарь, она в эту переменную кладёт относительную частоту соответствующего слова во всей коллекции. О том, что можно делать с этой переменной, будет рассказано в последующий разделах.\n",
        "\n",
        "Итак, теперь у Вас есть словарь. Его можно сохранять на диск, чтобы не пересоздавать каждый раз. Сохранять можно в бинарном виде:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iinehr0kkN0z"
      },
      "source": [
        "dictionary.save(dictionary_path='my_dictionary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0CwzurakN02"
      },
      "source": [
        "Либо в текстовом (в том случае, если Вы хотите посмотреть глазами на собранные данные):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-x7UbmgkN02"
      },
      "source": [
        "dictionary.save_text(dictionary_path='my_dictionary.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8ZFe7cBkN05"
      },
      "source": [
        "Сохранённый словарь можно загрузить обратно. Бинарный файл грузится так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh5VyiDmkN06"
      },
      "source": [
        "dictionary.load(dictionary_path='my_dictionary.dict')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmXsYv4FkN08"
      },
      "source": [
        "Текстовый - так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDnPbUDpkN09"
      },
      "source": [
        "dictionary.load_text(dictionary_path='my_dictionary.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfT13b7kkN0-"
      },
      "source": [
        "Кроме того, работая с текстовым словарём, Вы можете изменять его содержимое (менять значения поля value, например), после загрузки изменённого словаря в библиотеку эти правки будут учтены."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5a9sZookN0_"
      },
      "source": [
        "Последний момент: все методы создания BatchVectorizer автоматически генерируют словарь по умолчанию, доступ к которому можно получить, написав:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1FnELPzkN0_"
      },
      "source": [
        "batch_vectorizer.dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ034k3lkN1D"
      },
      "source": [
        "### 2. Обучение базовой модели PLSA с подсчётом перплексии."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-qogDEAkN1D"
      },
      "source": [
        "В этот момент Вам необходимо иметь следующие объекты:\n",
        "\n",
        "- директория названием my_collection_batches, а в ней - батчи и словарь в бинарном файле my_dictionary.dict, директория должна лежать рядом с этим ноутбуком;\n",
        "- переменная-словарь dictionary, в которой этот самый словарь есть (собран или загружен).\n",
        "- переменная batch_vectorizer (именно такая, какая создавалась выше).\n",
        "\n",
        "Если всё в порядке, можно приступить к созданию модели. Прежде всего рекомендуется ознакомиться со спецификацией класса ARTM, представляющего собой модель (https://bigartm.readthedocs.io/en/master/api_references/python_interface/artm_model.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "X3d8bsZ0mpQG"
      },
      "source": [
        "ARTM &ndash; это класс, представляющий собой Python API BigARTM, и позволяющий использовать практически все возможности библиотеки в стиле scikit-learn. Создадим две тематические модели для нашего эксперимента. Наиболее важным параметром модели является число тем. Опционально можно указать списки регуляризаторов и функционалов качества, которые следует использовать для данной модели. Если этого не сделать, то регуляризаторы и функционалы всегда можно добавить позднее. Обратите внимание, что каждая модель задаёт своё пространство имён для названий регуляризаторов и функционалов качества."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMAOm3UsnNp7"
      },
      "source": [
        "Затем для создания модели можно использовать следующий код:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSpzobEkN1E"
      },
      "source": [
        "model = artm.ARTM(num_topics=20, dictionary=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DJkliMekN1G"
      },
      "source": [
        "Таким образом, Вы создали модель, в которой была создана матрица $\\Phi$ размером \"число слов из Вашего словаря\" на число тем (20), она инициализирована случайным образом. Необходимо учитывать, что случайное приближение по умолчанию генерируется всегда с одним и тем же random seed (для воспроизводимости результатов). Если Вы хотите получить иное приближение, воспользуйтесь параметром seed класса ARTM (его различные неотрицательные целочисленные значения будут приводить к различным случайным начальным приближениям).\n",
        "\n",
        "С этого момента можно начинать процесс обучения модели, однако, как правило, сперва на модель навешиваются различные метрики качества моделирования. В данном примере мы воспользуемся наиболее распостраненным критерием - перплексией."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2cFaADltT9g"
      },
      "source": [
        "Остановимся на данной метрике подробнее.\n",
        "\n",
        "Перплексия равна экспоненте от минус логарифма\n",
        "правдоподобия, усредненного по всем словам всех документов:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IPVT9E61FNL"
      },
      "source": [
        "\\begin{aligned} {{{P}}}(D,p) = \\exp \\Bigl ( -\\frac{1}{n} L(\\varPhi ,\\varTheta ) \\Bigr ) = \\exp \\biggl ( -\\frac{1}{n} \\sum _{d\\in D} \\sum _{w\\in d} n_{dw} \\ln p(w\\ {\\vert }\\ d)\\biggr ). \\end{aligned}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaOpG5_H2vSF"
      },
      "source": [
        "Можно сказать, что это мера различности или неопределенности слов в тексте. \n",
        "\n",
        "Если подставить вместо распределения слов в документах равномерное распределение, то мы увидим, что перплексия равна просто мощности словаря.\n",
        "\n",
        "Если распределение слов неравномерно, то перплексия уменьшается по сравнению с тем значением, которое дает равномерное распределение. Еще можно сказать, что перплексия — это коэффициент ветвления текста, то есть сколько мы ожидаем различных слов после каждого слова в документе в среднем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c1n8eLMz-rK"
      },
      "source": [
        "Оперирование метриками происходит через поле scores класса ARTM, добавить метрику перплексии можно так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2p8dYhqkN1G"
      },
      "source": [
        "model.scores.add(artm.PerplexityScore(name='my_fisrt_perplexity_score',\n",
        "                                      dictionary=dictionary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThiuVKMgkN1J"
      },
      "source": [
        "Ответ на вопрос о смысле параметров метрики можно найти здесь http://bigartm.readthedocs.org/en/master/api_references/python_interface/scores.html. Важно запомнить, что подключать перплексию нужно именно так.\n",
        "\n",
        "**Важный момент**: если Вы попытаетесь создать вторую метрику с тем же именем - вызов будет проигнорирован (это позволяет безопасно перезапускать ячейки кода, создающие метрики в Jupyter notebook)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzNb6ZKLa1LA"
      },
      "source": [
        "Следующий шаг — инициализация моделей. Сделаем это по словарю, что означает, что\n",
        "- будет создана матрица $\\Phi$ с именем 'pwt', число строк и столбцов в ней будет взято исходя из числа слов в словаре и заданного в модели числа тем;\n",
        "- эта матрица будет заполнена случайными значениями из диапазона (0, 1) и нормализована.\n",
        "\n",
        "Словарь &ndash; это объект BigARTM, содержащий информацию о коллекции (словарь коллекции, различные величины и счётчики, связанные со словами). Создать словарь можно на основе папки с батчами. Затем собранный словарь можно сохранять на диск и позже подгрузить вновь."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwnGOs2SbHnF"
      },
      "source": [
        "model.initialize(dictionary=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JToJ0Q0a6Be"
      },
      "source": [
        "Теперь перейдём к главному действию - обучению модели. Сделать это можно одним из двух способов: онлайновым или оффлайновым. Обучение производят методы fit_online() и fit_offline() соответственно.\n",
        "\n",
        "- Оффлайновый алгоритм: много проходов по коллекции, один проход по документу (опционально), обновление Φ в конце каждого прохода. Используйте, если у Вас маленькая коллекция.\n",
        "\n",
        "- Онлайновый алгоритм: один проход по коллекции (опционально), много проходов по документу, обновление Φ раз в заданное количество батчей. Используйте при большой коллекции, и коллекции с быстро меняющейся тематикой.\n",
        "\n",
        "Параметры этих методов можно найти в ранее указанном документации http://bigartm.readthedocs.org/en/master/api_references/python_interface/artm_model.html. Мы воспользуемся оффлайновым обучением здесь и во всех остальных примерах. \n",
        "\n",
        "Итак, приступим к обучению:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V154ccgbkN1J"
      },
      "source": [
        "model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "takfET9VkN1L"
      },
      "source": [
        "Наверняка этот фрагмент кода работал дольше всех предыдущих. Вот мы и провели первый этап обучения модели, стоит посмотреть на перплексию. Для надо задействовать score_tracker. Это поле класса ARTM, отвечающее за хранение результатов подсчёта метрик. Он запоминает значения всех метрик на момент каждого обновления матрицы $\\Phi$. Обращение к метрикам производится по данным ранее именам.\n",
        "\n",
        "Требовать можно либо самое последнее значение:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXPTNlEpkN1M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "978d57c0-0e8f-43ae-8a6e-7b19552d7d09"
      },
      "source": [
        "print(model.score_tracker['my_fisrt_perplexity_score'].last_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1322.1502685546875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "747wQ5ljkN1O"
      },
      "source": [
        "Либо список всех значений:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQukl5F1kN1O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4c45199-9fa1-48ca-d902-4e97bba44491"
      },
      "source": [
        "print(model.score_tracker['my_fisrt_perplexity_score'].value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6667.97705078125, 2384.87646484375, 2005.3382568359375, 1683.2801513671875, 1531.7239990234375, 1448.349365234375, 1396.2391357421875, 1361.7174072265625, 1338.3148193359375, 1322.1502685546875]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB6jlNIbkN1Q"
      },
      "source": [
        "Если перплексия сошлась, то процесс обучения можно завершить. В противном случае надо продолжить. Как было отмечено, требование одной итерации прохода по документу - опциональное. И fit_online(), и fit_offline() могут делать столько итераций по документу, сколько захотите. Для этого надо задать это число в переменной-модели:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmCIH2LwkN1Q"
      },
      "source": [
        "model.num_document_passes = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usLTahcfkN1U"
      },
      "source": [
        "Все последующие вызовы методов обучения учтут это изменение. Запустим дальнейшее обучение:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxlMk8JokN1U"
      },
      "source": [
        "model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHfNVSurkN1W"
      },
      "source": [
        "Мы дообучили предыдущую модель, сделав ещё 15 итераций по коллекции, и на каждой из них 5 раз обрабатывая каждый документ.\n",
        "\n",
        "Дальше можно дообучать модель по аналогии. Напоследок, перед тем, как перейти ко следующему разделу: если в какой-то момент, Вы поняли, что модель выродилась, а Вы не хотите создавать новую - воспользуйтесь методом инициализации, который заполнит матрицу $\\Phi$ снова случайными числами, и ничего больше не тронет (ни ваших настроек регуляризаторов/метрик, ни историю значений метрик):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVQj8NadkN1X"
      },
      "source": [
        "model.initialize(dictionary=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaLx59OAkN1Z"
      },
      "source": [
        "Кстати, ровно этот метод и вызывает конструктор внутри себя, если получает на вход параметр dictionary. При этом изменение поля seed конструктора соответствующим образом скажется на вызове initialize().\n",
        "\n",
        "Заметим, что везде, где принимается переменная словарь, может приниматься и его имя-строка:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNQ1qXiSkN1a"
      },
      "source": [
        "model.initialize(dictionary=dictionary.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4ELngAvkN1c"
      },
      "source": [
        "### 3. Регуляризованная модель PLSA и новые метрики."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "_KVlFXPlkN1c"
      },
      "source": [
        "BigARTM - это проект, эффективно реализующий теорию аддитивной регуляризации тематических моделей К. В. Воронцова. АРТМ является более гибкой заменой существующего байесовского подхода. В основе теории лежат регуляризаторы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "-PdQz0_lkN1c"
      },
      "source": [
        "В библиотеке есть предопределённый набор регуляризаторов (при необходимости можно создавать новые, о создании регуляризаторов и метрик качества написано в отдельном соответствующем пособии). Сейчас мы будем учиться ими пользоваться.\n",
        "\n",
        "Предполагается, что все требования, предъявленные в начале предыдущего раздела, выполнены. Итак, создадим модель, добавим к ней метрику перплексии:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3veKqMXkN1d"
      },
      "source": [
        "model = artm.ARTM(num_topics=20, dictionary=dictionary, cache_theta=False)\n",
        "model.scores.add(artm.PerplexityScore(name='perplexity_score',\n",
        "                                      dictionary=dictionary))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q9tfPU_kN1f"
      },
      "source": [
        "Сразу следует отметить смысл флага cache_theta. Обрабатываемые коллекции могут иметь довольно большие размеры в смысле числа документов, и матрица $\\Theta$ для них может занимать слишком много места, что часто неприемлемо. Для этих целей существует флаг cache_theta, который позволяет запретить хранение это матрицы. По умолчанию матрица сохраняется, чтобы Вы имели возможность на неё посмотреть. В тех случаях, когда надо посмотреть на распределения документов, в $\\Theta$ в память не влезает, можно воспользоваться методов ARTM.transform() (о нём будет подробно рассказано далее)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "HbZxCcbDkN1g"
      },
      "source": [
        "Теперь попробуем добавить другие метрики, поскольку перплексия далеко не единственная и не лучшая (снова делаю отсылку к списку метрик и их параметров http://bigartm.readthedocs.org/en/master/api_references/python_interface/scores.html).\n",
        "\n",
        "Добавим метрики разреженности матриц $\\Phi$ и $\\Theta$, а также информацию о наиболее вероятных словах в каждой теме (топ-токенах):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj32TFOkkN1g"
      },
      "source": [
        "model.scores.add(artm.SparsityPhiScore(name='sparsity_phi_score'))\n",
        "model.scores.add(artm.SparsityThetaScore(name='sparsity_theta_score'))\n",
        "model.scores.add(artm.TopTokensScore(name='top_tokens_score'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "j3w6KIMwkN1i"
      },
      "source": [
        "Метрики обладают рядом полезных параметров. Например, они могут считаться по подмножествам тем - это часто бывает полезным. Давайте будем отдельно считать разреженность первых десяти тем в матрице $\\Phi$. Но есть проблема: темы идентифицируются своими именами, которые не были заданы. Если бы мы задали параметр topic_names в конструкторе модели, такой вопрос бы не встал. А мы задали только num_topics. Однако решение имеется: библиотека сгенерировала нужные имена и сама положила их в поле topic_names, можно ими воспользоваться:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4R0ozpnkN1j"
      },
      "source": [
        "model.scores.add(artm.SparsityPhiScore(name='sparsity_phi_score_10_topics', topic_names=model.topic_names[0: 9]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "9RO60n5pkN1m"
      },
      "source": [
        "Конечно, если бы общая разреженность модели была бы нам неинтересна, мы могли бы просто модифицировать первую метрику, а не вводить новую."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "mOEcfuZtkN1o"
      },
      "source": [
        "Но, допустим, что нам интересна и общая разреженность модели, поэтому оставим всё как есть. Тем не менее Вам следует запомнить, что все параметры метрик, модели (и регуляризаторов, о которых будет рассказано далее) могут быть выставлены или заменены путём прямого обращения к полю, как это показано в коде выше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgW5a3nAkN1o"
      },
      "source": [
        "Например, потребуем, чтобы метрика топ-токенов показывала нам 12 наиболее вероятных слов в каждой теме:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TUIrF0zkN1p"
      },
      "source": [
        "model.num_tokens = 12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "7Cll6n2fkN1r"
      },
      "source": [
        "Итак, мы получили модель, покрытую необходимыми метриками, можно запускать процесс обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YAKZ_zvkN1r"
      },
      "source": [
        "model.initialize(dictionary=dictionary)\n",
        "model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Kr0xhkF2kN1u"
      },
      "source": [
        "Этот код уже встречался в предыдущем разделе. Но теперь можно посмотреть значения новых подключенных метрик:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-90wbyWkN1u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c7a1a026-d31d-49be-aed3-525d91df8b57"
      },
      "source": [
        "print(model.score_tracker['perplexity_score'].value)      # .last_value\n",
        "print(model.score_tracker['sparsity_phi_score'].value)    # .last_value\n",
        "print(model.score_tracker['sparsity_theta_score'].value)  # .last_value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6667.97705078125, 2384.87646484375, 2005.3382568359375, 1683.2801513671875, 1531.7239990234375, 1448.349365234375, 1396.2391357421875, 1361.7174072265625, 1338.3148193359375, 1322.1502685546875]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0005357660120353103, 0.00375036196783185, 0.010338835418224335, 0.020721111446619034, 0.03410802036523819, 0.050419922918081284]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gueI-B0YkN1w"
      },
      "source": [
        "Как видно, во всех метриках ничего не изменилось. Однако мы забыли про топ-токены. Здесь надо действовать несколько аккуратнее: метрика хранит данные на момент всех обновлений матрицы $\\Phi$. Предположим, что нам нужны только самые последние данные. Тогда обратимся к полю last_tokens. Это словарь, в котором ключ - имя темы, а значение - список топ-слов этой темы.\n",
        "\n",
        "**Важный момент**: метрики выгружаются из ядра при каждом обращении, поэтому для таких больших метрик, как топ-слова (или ядровые характеристики, о которых можно прочитать по данным выше ссылкам), лучше завести переменную, в которую Вы один раз всё выгрузите, а потом уже работать с ней. Итак, просмотрим топ-слова последовательно в цикле по именам тем модели:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNo7NImDkN1x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "07e8dca0-a864-4667-fc7a-683e56c16627"
      },
      "source": [
        "saved_top_tokens = model.score_tracker['top_tokens_score'].last_tokens\n",
        "\n",
        "for topic_name in model.topic_names:\n",
        "    print(saved_top_tokens[topic_name])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tax', 'party', 'bush', 'federal', 'court', 'democratic', 'political', 'economic', 'social', 'law']\n",
            "['iraq', 'war', 'military', 'troops', 'soldiers', 'killed', 'iraqi', 'forces', 'baghdad', 'army']\n",
            "['november', 'poll', 'house', 'governor', 'electoral', 'account', 'senate', 'republicans', 'polls', 'contact']\n",
            "['senate', 'race', 'carson', 'republican', 'elections', 'oklahoma', 'coburn', 'colorado', 'campaign', 'gop']\n",
            "['election', 'specter', 'toomey', 'workers', 'health', 'time', 'people', 'oil', 'bush', 'signs']\n",
            "['kerry', 'cheney', 'john', 'president', 'kerrys', 'america', 'convention', 'speech', 'general', 'people']\n",
            "['race', 'district', 'state', 'nader', 'ballot', 'seat', 'candidate', 'party', 'elections', 'democrats']\n",
            "['administration', 'bush', 'white', 'house', 'commission', 'president', 'report', 'jobs', 'billion', 'year']\n",
            "['campaign', 'media', 'party', 'democratic', 'ads', 'union', 'national', 'unions', 'television', 'political']\n",
            "['house', 'million', 'money', 'delay', 'committee', 'republican', 'elections', 'democratic', 'democrats', 'races']\n",
            "['november', 'voting', 'vote', 'kerry', 'house', 'polls', 'bush', 'electoral', 'senate', 'account']\n",
            "['iraq', 'war', 'bush', 'american', 'saddam', 'iraqi', 'united', 'intelligence', 'administration', 'weapons']\n",
            "['bush', 'poll', 'kerry', 'voters', 'polls', 'general', 'results', 'polling', 'numbers', 'percent']\n",
            "['media', 'time', 'herseth', 'house', 'people', 'blogs', 'bunning', 'reporters', 'election', 'read']\n",
            "['bush', 'kerry', 'general', 'ohio', 'states', 'state', 'oct', 'debate', 'voters', 'michigan']\n",
            "['bush', 'bushs', 'war', 'president', 'iraq', 'administration', 'george', 'news', 'people', 'political']\n",
            "['reagan', 'years', 'people', 'women', 'rights', 'news', 'bush', 'family', 'science', 'cell']\n",
            "['dean', 'edwards', 'primary', 'clark', 'democratic', 'iowa', 'kerry', 'gephardt', 'lieberman', 'jan']\n",
            "['kerry', 'percent', 'democratic', 'john', 'democrats', 'campaign', 'nominee', 'south', 'vote', 'candidate']\n",
            "['republicans', 'republican', 'democrats', 'gop', 'state', 'vote', 'marriage', 'governor', 'party', 'gay']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY-4ZRy2kN1z"
      },
      "source": [
        "Вероятно, темы получились не самые лучшие. Как раз для цели улучшения моделей существуют регуляризаторы, задача которых - сделать модель более качественной, интерпретируемой.\n",
        "\n",
        "Списки регуляризаторов и их параметров можно посмотреть здесь http://bigartm.readthedocs.org/en/master/api_references/python_interface/regularizers.html. Код работы с регуляризаторами очень похож на код работы с метриками. Добавим в модель три регуляризатора: разреживание $\\Phi$, разреживание $\\Theta$ и декорреляция тем. Последний старается сделать темы как можно более различными."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrv0V6j-kN1z"
      },
      "source": [
        "model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='sparse_phi_regularizer'))\n",
        "model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='sparse_theta_regularizer'))\n",
        "model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "imLgylGDkN12"
      },
      "source": [
        "Возможно, у Вас вызывает вопрос имя регуляризатора SmoothSparsePhi\\Theta - получается, что он и сглаживает, и разреживает? Именно так. Он может и то, и то, его действия будут зависеть от того, каким Вы зададите его коэффициент регуляризации $\\tau$. $\\tau$ > 0 - будет сглаживать, $\\tau$ < 0 - разреживать. По умолчанию все регуляризаторы получают $\\tau$ = 1.0, что, как правило, совершенно не подходит. Выбор подходящего $\\tau$ - эвристика, иногда приходится провести десятки опытов, чтобы подобрать хорошие значений. Это экспериментальная работа, которая здесь рассматриваться не будет. Вместо этого посмотрим на технические детали:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ip1RUVJkN13"
      },
      "source": [
        "model.regularizers['sparse_phi_regularizer'].tau = -1.0\n",
        "model.regularizers['sparse_theta_regularizer'].tau = -0.5\n",
        "model.regularizers['decorrelator_phi_regularizer'].tau = 1e+5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "-89pN1yPkN17"
      },
      "source": [
        "Выставленные значения стандартны, но при неблагоприятном стечении обстоятельств могут либо не оказать на модель существенного влияния, либо существенно её ухудшить.\n",
        "\n",
        "Ещё раз обращаю Ваше внимание, что выставление и замена параметров регуляризаторов полностью аналогично тому, как это происходит у метрик.\n",
        "\n",
        "Запустим обучение модели повторно:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMQgCg4bkN17"
      },
      "source": [
        "model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Du59VTYqkN19"
      },
      "source": [
        "Дальше можно снова смотреть на метрики, поправлять коэффициенты $\\tau$ регуляризаторов и т.д.\n",
        "Регуляризаторам, как и метрикам, тоже можно задать, какие темы можно трогать, а какие - нельзя. Делается это в полной аналогии с тем, как мы проделали это для метрик."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58e96sVLkN19"
      },
      "source": [
        "Вернёмся теперь к словарям. Но для начала небольшое отступление. Рассмотрим принцип работы регуляризатора сглаживания/разреживания $\\Phi$. Он просто прибавляет ко всем счётчикам одну и ту же величину $\\tau$, что может оказаться неподходящей нам стратегией. Возможный сценарий: необходимость разреживания части слов при сглаживании другой части и игнорировании всех остальных. Для примера, хотим разреживать слова про магию, сглаживать - про котов, а остальные не трогать.\n",
        "\n",
        "В этой ситуации необходимо использовать словари.\n",
        "\n",
        "Вспомним про поле value, которое соответствует каждому слову. А также про то, что регуляризатор сглаживания/разреживания $\\Phi$ имеет поле dictionary. Если Вы зададите это поле, то регуляризатор будет прибавлять к счётчикам не $\\tau$, а $\\tau$ * value для данного слова. Таким образом, если $\\tau$ взять равным, например, единице, словам о магии выставить value = -1.0, словам о котах - 1.0, а всем остальным словам - 0.0, то мы получим ровно то, что требовалось.\n",
        "\n",
        "Остался один момент: как заменить эти самые value. Об этом говорилось во вводной части, вспомним о методах словарей Dictionary.save_text() и Dictionary.load_text().\n",
        "\n",
        "Последовательность действий следующая:\n",
        "\n",
        "- выгружаете словарь в текстовом виде;\n",
        "- открываете его, каждая строка - одно слово, в строке 5 значений: слово - модальность - value - token_tf - token_df (это всё написано в первой строке-заголовке);\n",
        "- не обращайте внимания ни на что, кроме слова и его value; найдите интересующие Вас слова и выставьте им нужные значения value;\n",
        "- загрузите словарь обратно.\n",
        "\n",
        "\n",
        "После редактирования Ваш файл со словарём может выглядеть так (схематично):\n",
        "\n",
        "котик  | что-то  |  1.0  |  что-то  |  что-то\n",
        "\n",
        "пиво   | что-то  |  0.0  |  что-то  |  что-то\n",
        "\n",
        "посох  | что-то  | -1.0  |  что-то  |  что-то\n",
        "\n",
        "киса   | что-то  |  1.0  |  что-то  |  что-то\n",
        "\n",
        "мерлин | что-то  | -1.0  |  что-то  |  что-то\n",
        "\n",
        "москва | что-то  |  0.0  |  что-то  |  что-то"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqKdI43lkN1-"
      },
      "source": [
        "Весь необходимый для проведения описанных операций код уже был показан ранее. На всякий случай посмотрим, как создать регуляризатор со словарём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDrpOfjSkN1-"
      },
      "source": [
        "model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='smooth_sparse_phi_regularizer', dictionary=dictionary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wjo8RGLkN2A"
      },
      "source": [
        "На этом данный раздел окончен, можно двигаться далее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRq1YujPkN2A"
      },
      "source": [
        "### 4. Построение мультимодальной тематической модели с регуляризацией и оцениванием качества; метод ARTM.transform()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "6ZYF_2vYkN2A"
      },
      "source": [
        "Теперь перейдём к более сложным случаям. В прошлом разделе было упомянуто понятие модальности. Это нечто, соответствующее каждому слову. Я бы определил это, как вид слова. Бывают слова текста, бывают слова, из которых состоит заголовок. А также слова-имена авторов текста, и даже картинку, если её перекодировать в текст, можно считать набором слов, и слова эти будут типа \"слова из которых состоит картинка\". И таких видов слов можно придумать очень много.\n",
        "\n",
        "Так вот, в BigARTM каждое слово имеет тип модальность. Обозначается она не интуитивно - class_id. Ничего общего с классификацией это не имеет, просто неудачное название, которое уже поздно менять. У каждого слова есть такой class_id, Вы всегда можете задать его сами, либо же библиотека автоматически задаст class_id = '@default_class' (если Вы смотрели внутрь словарей, то, наверняка, видели эту конструкцию). Это - тип обычных слов, тип по умолчанию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "6x5vP8rlkN2B"
      },
      "source": [
        "В большинстве случаев модальности не потребуются, но есть такие ситуации, когда они незаменимы. Например, при классификации документов. Собственно, именно этот пример мы и рассмотрим."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEDeb5mTkN2B"
      },
      "source": [
        "Все данные придётся пересоздавать с учётом наличия модальностей. От Вас потребуется создание файла в формате Vowpal Wabbit, в котором каждая строка - это документ, а каждый документ состоит из обычных слов и слов-меток классов, к которым относится документ. \n",
        "\n",
        "Пример:\n",
        "doc_100500 |@default_class aaa:2 bbb:4 ccc ddd:6 |@labels_class class_1 class_6\n",
        "\n",
        "Всё это подробно описано здесь http://bigartm.readthedocs.org/en/master/formats.html.\n",
        "\n",
        "Теперь проделайте с этим файлом все необходимые манипуляции из вводной части, чтобы получить нужные батчи и словарь."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryiUjjcQkN2B"
      },
      "source": [
        "Далее, Вам надо объяснить модели, какие у Вас есть модальности, и какие степени влияния на модель Вы хотите им задать. Степень влияния - это коэффициент модальности $\\tau_m$. Модель по умолчанию использует только слова модальности '@default_class' и её берёт с $\\tau_m$ = 1.0. Хотите использовать другие модальности и веса - надо задать эти требования в конструкторе модели следующим кодом:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2_tvBWUkN2C"
      },
      "source": [
        "model = artm.ARTM(num_topics=20, class_ids={'@default_class': 1.0, '@labels_class': 5.0}, cache_theta=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYbh4o4gkN2E"
      },
      "source": [
        "Итак, мы попросили модель учитывать эти две модальности, причём метки классов сделать в 5 раз более влиятельными, чем обычные слова. Отмечу, что если в вашем файле с данными были ещё модальности, а Вы их тут не отметили - они не будут учтены. Опять же, если Вы отметите в конструкторе модальности, которых нет в данных - случится то же самое.\n",
        "\n",
        "Разумеется, поле class_ids, как и все остальные, является переопределяемым, Вы всегда можете изменить веса модальностей:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woZ1HAcHkN2E"
      },
      "source": [
        "model.class_ids = {'@default_class': 1.0, '@labels_class': 50.0}  # model.class_ids['@labels_class'] = 50.0 --- NO!!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nBwEvJdkN2G"
      },
      "source": [
        "Обновлять веса надо именно так, задавая весь словарь, не надо пытаться обратиться по ключу к отдельной модальности, class_ids обновляется с помощью словаря, но сама словарём не является (словарь - в смысле Python dict)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "7jDpVqA3kN2G"
      },
      "source": [
        "При следующем запуске fit_offline() или fit_online() эта информация будет учтена.\n",
        "\n",
        "Теперь к модели надо подключить регуляризаторы и метрики качества. Весь это процесс уже был рассмотрен, за исключением одного момента. Все метрики на матрице $\\Phi$ (а также перплексия) и регуляризаторы $\\Phi$ имеют поля для работы модальностями. Т. е. в этих полях Вы можете определить, с каким модальностями метрика/регуляризатор должна работать, остальные будут проигнорированы (по аналогии с полем topic_names для тем).\n",
        "\n",
        "Поле модальности может быть либо class_id, либо class_ids. Первое - это строка с именем одной модальности, с которой надо работать, второе - список строк с такими модальностями.\n",
        "\n",
        "**Важный момент** со значениями по умолчанию. Для class_id отсутствие заданного Вами значения означает class_id = '@default_class'. Для class_ids отсутствие значения означает использование всех имеющихся в модели модальностей.\n",
        "\n",
        "Посмотреть информацию детально о каждой метрике и каждом регуляризаторе можно по уже данным ранее ссылках http://bigartm.readthedocs.org/en/master/api_references/python_interface/regularizers.html и http://bigartm.readthedocs.org/en/master/api_references/python_interface/scores.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "3aBCG7UOkN2H"
      },
      "source": [
        "Давайте добавим в модель метрику разреженности $\\Phi$ для модальности меток классов, а также регуляризаторы декорреляции тем для каждой из модальностей, после чего запустим процесс обучения модели:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTPR-eaCkN2H"
      },
      "source": [
        "model.scores.add(artm.SparsityPhiScore(name='sparsity_phi_score', class_id='@labels_class'))\n",
        "\n",
        "model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_def', class_ids=['@default_class']))\n",
        "model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_lab', class_ids=['@labels_class']))\n",
        "\n",
        "model.initialize(dictionary=dictionary)\n",
        "model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX3HkLvRkN2L"
      },
      "source": [
        "Итак, работы по дальнейшей настройке модели, подбору коэффициентов регуляризации, весов модальностей и просмотра метрик остаются Вам. Сейчас же перейдём к использованию обученной модели для классификации тестовых данных.\n",
        "\n",
        "#### Классификация тестовых данных с помощью предобученной модели\n",
        "\n",
        "Напомню, что в задаче классификации у Вас есть обучающие данные (коллекция, на которой Вы тренировали модель, где для каждого документа модели известны его метки классов) и данные тестовые, метки которых известны Вам, но не сообщаются модели. Эти скрытые метки модель и должна предсказать, глядя на тестовые документы, а Ваша задача - взять верные ответы и то, что Вам выдала модель, и сравнить, например, посчитав AUC.\n",
        "\n",
        "Подсчёт AUC или ещё каких либо метрик - это Ваше дело, мы этого касаться не будем. А мы займёмся получением для новых документов векторов p(c|d) длиной в количество классов, где каждый элемент - вероятность класса c для данного документа d.\n",
        "\n",
        "Итак, у нас имеется модель. Предполагается, что тестовые документы были убраны в отдельный файл в формате Vowpal Wabbit, на основе которого Вы сумели сгенерировать батчи, которые описываются переменной batch_vectorizer_test. Также предполагается, что сохранили Вы тестовые батчи в отдельную директорию (не в ту, в которую сохранялись обучающие батчи).\n",
        "\n",
        "Ваши тестовые документы не должны содержать информацию о метках классов (а именно: в тестовом файле не должно быть строки '|@labels_class'), также тестовые документы не содержат слов, которых не было в документах обучающих, иначе такие слова будут проигнорированы.\n",
        "\n",
        "Если все эти условия выполнены, можно переходить к использованию ARTM.transform(), который позволяет для всех документов из данного объекта BatchVectorizer получить матрицу вероятностей p(t|d) (т. е. $\\Theta$), либо матрицу p(c|d) для любой указанной модальности.\n",
        "\n",
        "Чтобы получить $\\Theta$ делаем так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp582unakN2L"
      },
      "source": [
        "theta_test = model.transform(batch_vectorizer=batch_vectorizer) # !FIX_ME: здесь на самом деле д.б. batch_vectorizer=batch_vectorizer_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I7GYobOjj0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "1cb47274-aa3d-49ee-fe5c-fdb22cf1552c"
      },
      "source": [
        "theta_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3001</th>\n",
              "      <th>3002</th>\n",
              "      <th>3003</th>\n",
              "      <th>3004</th>\n",
              "      <th>3005</th>\n",
              "      <th>3006</th>\n",
              "      <th>3007</th>\n",
              "      <th>3008</th>\n",
              "      <th>3009</th>\n",
              "      <th>3010</th>\n",
              "      <th>3011</th>\n",
              "      <th>3012</th>\n",
              "      <th>3013</th>\n",
              "      <th>3014</th>\n",
              "      <th>3015</th>\n",
              "      <th>3016</th>\n",
              "      <th>3017</th>\n",
              "      <th>3018</th>\n",
              "      <th>3019</th>\n",
              "      <th>3020</th>\n",
              "      <th>3021</th>\n",
              "      <th>3022</th>\n",
              "      <th>3023</th>\n",
              "      <th>3024</th>\n",
              "      <th>3025</th>\n",
              "      <th>3026</th>\n",
              "      <th>3027</th>\n",
              "      <th>3028</th>\n",
              "      <th>3029</th>\n",
              "      <th>3030</th>\n",
              "      <th>3031</th>\n",
              "      <th>3032</th>\n",
              "      <th>3033</th>\n",
              "      <th>3034</th>\n",
              "      <th>3035</th>\n",
              "      <th>3036</th>\n",
              "      <th>3037</th>\n",
              "      <th>3038</th>\n",
              "      <th>3039</th>\n",
              "      <th>3040</th>\n",
              "      <th>...</th>\n",
              "      <th>2961</th>\n",
              "      <th>2962</th>\n",
              "      <th>2963</th>\n",
              "      <th>2964</th>\n",
              "      <th>2965</th>\n",
              "      <th>2966</th>\n",
              "      <th>2967</th>\n",
              "      <th>2968</th>\n",
              "      <th>2969</th>\n",
              "      <th>2970</th>\n",
              "      <th>2971</th>\n",
              "      <th>2972</th>\n",
              "      <th>2973</th>\n",
              "      <th>2974</th>\n",
              "      <th>2975</th>\n",
              "      <th>2976</th>\n",
              "      <th>2977</th>\n",
              "      <th>2978</th>\n",
              "      <th>2979</th>\n",
              "      <th>2980</th>\n",
              "      <th>2981</th>\n",
              "      <th>2982</th>\n",
              "      <th>2983</th>\n",
              "      <th>2984</th>\n",
              "      <th>2985</th>\n",
              "      <th>2986</th>\n",
              "      <th>2987</th>\n",
              "      <th>2988</th>\n",
              "      <th>2989</th>\n",
              "      <th>2990</th>\n",
              "      <th>2991</th>\n",
              "      <th>2992</th>\n",
              "      <th>2993</th>\n",
              "      <th>2994</th>\n",
              "      <th>2995</th>\n",
              "      <th>2996</th>\n",
              "      <th>2997</th>\n",
              "      <th>2998</th>\n",
              "      <th>2999</th>\n",
              "      <th>3000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>topic_0</th>\n",
              "      <td>7.655325e-02</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>7.447137e-03</td>\n",
              "      <td>0.152995</td>\n",
              "      <td>0.006617</td>\n",
              "      <td>2.318493e-07</td>\n",
              "      <td>0.038358</td>\n",
              "      <td>1.904449e-04</td>\n",
              "      <td>0.000533</td>\n",
              "      <td>0.001690</td>\n",
              "      <td>2.065675e-02</td>\n",
              "      <td>0.002016</td>\n",
              "      <td>3.367082e-04</td>\n",
              "      <td>5.667984e-03</td>\n",
              "      <td>4.527970e-05</td>\n",
              "      <td>6.594907e-04</td>\n",
              "      <td>0.020253</td>\n",
              "      <td>3.109395e-05</td>\n",
              "      <td>8.745365e-07</td>\n",
              "      <td>2.161548e-02</td>\n",
              "      <td>4.770815e-07</td>\n",
              "      <td>0.007953</td>\n",
              "      <td>0.009270</td>\n",
              "      <td>0.192351</td>\n",
              "      <td>5.235600e-02</td>\n",
              "      <td>9.059112e-04</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>1.590523e-05</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>0.060173</td>\n",
              "      <td>4.845247e-02</td>\n",
              "      <td>6.567059e-03</td>\n",
              "      <td>1.974827e-06</td>\n",
              "      <td>4.600245e-04</td>\n",
              "      <td>0.001597</td>\n",
              "      <td>1.120104e-04</td>\n",
              "      <td>0.028457</td>\n",
              "      <td>2.511142e-04</td>\n",
              "      <td>0.001784</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009650</td>\n",
              "      <td>0.129140</td>\n",
              "      <td>2.630012e-01</td>\n",
              "      <td>0.004320</td>\n",
              "      <td>0.120311</td>\n",
              "      <td>0.003268</td>\n",
              "      <td>0.001049</td>\n",
              "      <td>2.410757e-03</td>\n",
              "      <td>7.092132e-08</td>\n",
              "      <td>0.008862</td>\n",
              "      <td>0.001924</td>\n",
              "      <td>2.005550e-06</td>\n",
              "      <td>8.369546e-05</td>\n",
              "      <td>0.406437</td>\n",
              "      <td>0.001264</td>\n",
              "      <td>6.838077e-06</td>\n",
              "      <td>1.486081e-02</td>\n",
              "      <td>1.510659e-03</td>\n",
              "      <td>0.087043</td>\n",
              "      <td>0.005285</td>\n",
              "      <td>0.001789</td>\n",
              "      <td>0.003608</td>\n",
              "      <td>7.669974e-03</td>\n",
              "      <td>1.785914e-03</td>\n",
              "      <td>3.697325e-02</td>\n",
              "      <td>8.757924e-03</td>\n",
              "      <td>0.004667</td>\n",
              "      <td>0.024749</td>\n",
              "      <td>0.000371</td>\n",
              "      <td>4.149544e-02</td>\n",
              "      <td>1.160984e-04</td>\n",
              "      <td>5.323216e-06</td>\n",
              "      <td>0.001099</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.015684</td>\n",
              "      <td>0.006181</td>\n",
              "      <td>6.319681e-02</td>\n",
              "      <td>3.868793e-04</td>\n",
              "      <td>0.011725</td>\n",
              "      <td>1.808449e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_1</th>\n",
              "      <td>5.757245e-02</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>6.182407e-05</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>1.626846e-08</td>\n",
              "      <td>0.014565</td>\n",
              "      <td>3.679957e-07</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>1.132987e-02</td>\n",
              "      <td>0.006398</td>\n",
              "      <td>5.526313e-02</td>\n",
              "      <td>4.532640e-02</td>\n",
              "      <td>1.300115e-02</td>\n",
              "      <td>7.421032e-02</td>\n",
              "      <td>0.007037</td>\n",
              "      <td>6.997697e-05</td>\n",
              "      <td>4.639028e-02</td>\n",
              "      <td>3.296635e-04</td>\n",
              "      <td>6.686857e-02</td>\n",
              "      <td>0.648937</td>\n",
              "      <td>0.470059</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>5.619323e-06</td>\n",
              "      <td>1.594649e-02</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>3.974797e-05</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>8.724500e-03</td>\n",
              "      <td>8.543863e-03</td>\n",
              "      <td>1.146246e-04</td>\n",
              "      <td>8.614657e-05</td>\n",
              "      <td>0.003369</td>\n",
              "      <td>2.308877e-07</td>\n",
              "      <td>0.001501</td>\n",
              "      <td>1.270256e-03</td>\n",
              "      <td>0.013851</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.002754</td>\n",
              "      <td>2.063666e-04</td>\n",
              "      <td>0.042498</td>\n",
              "      <td>0.010751</td>\n",
              "      <td>0.220013</td>\n",
              "      <td>0.338224</td>\n",
              "      <td>7.795050e-01</td>\n",
              "      <td>5.082158e-06</td>\n",
              "      <td>0.017574</td>\n",
              "      <td>0.009068</td>\n",
              "      <td>8.142557e-07</td>\n",
              "      <td>8.602562e-01</td>\n",
              "      <td>0.017726</td>\n",
              "      <td>0.004084</td>\n",
              "      <td>9.718580e-01</td>\n",
              "      <td>2.991189e-03</td>\n",
              "      <td>1.798860e-04</td>\n",
              "      <td>0.001594</td>\n",
              "      <td>0.046286</td>\n",
              "      <td>0.001931</td>\n",
              "      <td>0.000634</td>\n",
              "      <td>1.916609e-01</td>\n",
              "      <td>1.147833e-01</td>\n",
              "      <td>1.968264e-04</td>\n",
              "      <td>2.286436e-01</td>\n",
              "      <td>0.179498</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>7.940481e-04</td>\n",
              "      <td>3.951371e-07</td>\n",
              "      <td>1.173149e-07</td>\n",
              "      <td>0.155024</td>\n",
              "      <td>0.005878</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>3.005372e-02</td>\n",
              "      <td>1.559845e-01</td>\n",
              "      <td>0.000511</td>\n",
              "      <td>2.141559e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_2</th>\n",
              "      <td>8.684420e-08</td>\n",
              "      <td>0.031961</td>\n",
              "      <td>6.618644e-07</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>0.001909</td>\n",
              "      <td>5.777651e-01</td>\n",
              "      <td>0.000501</td>\n",
              "      <td>2.107283e-12</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>2.485581e-07</td>\n",
              "      <td>0.000640</td>\n",
              "      <td>1.566122e-08</td>\n",
              "      <td>2.555126e-10</td>\n",
              "      <td>1.766219e-10</td>\n",
              "      <td>5.107622e-11</td>\n",
              "      <td>0.209466</td>\n",
              "      <td>2.472994e-09</td>\n",
              "      <td>1.581099e-02</td>\n",
              "      <td>4.731986e-07</td>\n",
              "      <td>5.712002e-07</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000861</td>\n",
              "      <td>3.681708e-07</td>\n",
              "      <td>6.571203e-09</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>9.520856e-10</td>\n",
              "      <td>0.304582</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>3.808741e-08</td>\n",
              "      <td>3.744420e-09</td>\n",
              "      <td>7.415165e-08</td>\n",
              "      <td>3.644529e-08</td>\n",
              "      <td>0.018415</td>\n",
              "      <td>2.821725e-12</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>4.207837e-08</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>...</td>\n",
              "      <td>0.394789</td>\n",
              "      <td>0.000276</td>\n",
              "      <td>4.533514e-11</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.002368</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>4.804630e-08</td>\n",
              "      <td>5.672026e-03</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>0.008826</td>\n",
              "      <td>6.966792e-01</td>\n",
              "      <td>1.208034e-08</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>1.063861e-10</td>\n",
              "      <td>7.608694e-07</td>\n",
              "      <td>1.886843e-09</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.006566</td>\n",
              "      <td>0.354105</td>\n",
              "      <td>2.389377e-07</td>\n",
              "      <td>1.477903e-07</td>\n",
              "      <td>8.889979e-08</td>\n",
              "      <td>5.586990e-10</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.011439</td>\n",
              "      <td>0.004596</td>\n",
              "      <td>3.908717e-07</td>\n",
              "      <td>4.929503e-02</td>\n",
              "      <td>1.913453e-02</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.424630</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>0.587406</td>\n",
              "      <td>2.204424e-09</td>\n",
              "      <td>1.605920e-07</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>7.136307e-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_3</th>\n",
              "      <td>9.985089e-03</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>6.323186e-04</td>\n",
              "      <td>0.054421</td>\n",
              "      <td>0.014808</td>\n",
              "      <td>1.569790e-04</td>\n",
              "      <td>0.054855</td>\n",
              "      <td>1.144827e-01</td>\n",
              "      <td>0.056717</td>\n",
              "      <td>0.001840</td>\n",
              "      <td>7.507964e-04</td>\n",
              "      <td>0.003619</td>\n",
              "      <td>1.348697e-02</td>\n",
              "      <td>3.336097e-04</td>\n",
              "      <td>1.620434e-03</td>\n",
              "      <td>2.383213e-03</td>\n",
              "      <td>0.006471</td>\n",
              "      <td>2.018046e-04</td>\n",
              "      <td>1.832157e-01</td>\n",
              "      <td>7.289042e-01</td>\n",
              "      <td>1.857921e-04</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.041925</td>\n",
              "      <td>0.040280</td>\n",
              "      <td>1.487898e-01</td>\n",
              "      <td>1.497199e-05</td>\n",
              "      <td>0.213610</td>\n",
              "      <td>2.717001e-06</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>2.362975e-03</td>\n",
              "      <td>1.964082e-02</td>\n",
              "      <td>1.120636e-05</td>\n",
              "      <td>9.247091e-04</td>\n",
              "      <td>0.002850</td>\n",
              "      <td>3.463581e-01</td>\n",
              "      <td>0.608954</td>\n",
              "      <td>6.613769e-04</td>\n",
              "      <td>0.037124</td>\n",
              "      <td>0.002190</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000497</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>4.333331e-03</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.007974</td>\n",
              "      <td>0.004199</td>\n",
              "      <td>0.001177</td>\n",
              "      <td>4.150070e-05</td>\n",
              "      <td>1.949820e-02</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>6.236014e-06</td>\n",
              "      <td>4.014909e-05</td>\n",
              "      <td>0.006911</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>5.222262e-08</td>\n",
              "      <td>4.773469e-02</td>\n",
              "      <td>4.270081e-02</td>\n",
              "      <td>0.367130</td>\n",
              "      <td>0.001091</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.001670</td>\n",
              "      <td>9.989439e-03</td>\n",
              "      <td>2.578859e-02</td>\n",
              "      <td>4.535098e-02</td>\n",
              "      <td>7.998887e-02</td>\n",
              "      <td>0.010290</td>\n",
              "      <td>0.101881</td>\n",
              "      <td>0.000625</td>\n",
              "      <td>1.666463e-04</td>\n",
              "      <td>1.030230e-03</td>\n",
              "      <td>1.427810e-09</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.000522</td>\n",
              "      <td>0.000225</td>\n",
              "      <td>7.260778e-05</td>\n",
              "      <td>4.724808e-04</td>\n",
              "      <td>0.000952</td>\n",
              "      <td>2.206358e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_4</th>\n",
              "      <td>4.206443e-01</td>\n",
              "      <td>0.023032</td>\n",
              "      <td>8.373030e-02</td>\n",
              "      <td>0.000997</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>6.870717e-08</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>8.834111e-07</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.001247</td>\n",
              "      <td>2.343993e-02</td>\n",
              "      <td>0.005458</td>\n",
              "      <td>7.418192e-03</td>\n",
              "      <td>1.068938e-01</td>\n",
              "      <td>2.684591e-05</td>\n",
              "      <td>1.541522e-03</td>\n",
              "      <td>0.007399</td>\n",
              "      <td>3.501915e-06</td>\n",
              "      <td>1.122000e-02</td>\n",
              "      <td>5.301623e-03</td>\n",
              "      <td>1.758620e-03</td>\n",
              "      <td>0.018212</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>2.399881e-03</td>\n",
              "      <td>3.567913e-03</td>\n",
              "      <td>0.006601</td>\n",
              "      <td>3.036800e-06</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>0.007670</td>\n",
              "      <td>2.060438e-02</td>\n",
              "      <td>9.349939e-03</td>\n",
              "      <td>8.177754e-05</td>\n",
              "      <td>2.117002e-03</td>\n",
              "      <td>0.134466</td>\n",
              "      <td>2.224652e-03</td>\n",
              "      <td>0.004169</td>\n",
              "      <td>6.616707e-05</td>\n",
              "      <td>0.082304</td>\n",
              "      <td>0.002502</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006459</td>\n",
              "      <td>0.009321</td>\n",
              "      <td>4.042792e-03</td>\n",
              "      <td>0.001919</td>\n",
              "      <td>0.265083</td>\n",
              "      <td>0.006940</td>\n",
              "      <td>0.000459</td>\n",
              "      <td>3.374115e-03</td>\n",
              "      <td>6.233720e-05</td>\n",
              "      <td>0.057157</td>\n",
              "      <td>0.038070</td>\n",
              "      <td>3.602958e-06</td>\n",
              "      <td>1.984352e-02</td>\n",
              "      <td>0.450607</td>\n",
              "      <td>0.013420</td>\n",
              "      <td>3.857802e-03</td>\n",
              "      <td>1.269763e-02</td>\n",
              "      <td>4.213771e-03</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.265491</td>\n",
              "      <td>0.001361</td>\n",
              "      <td>0.000697</td>\n",
              "      <td>7.903742e-03</td>\n",
              "      <td>3.648249e-02</td>\n",
              "      <td>1.198341e-01</td>\n",
              "      <td>1.156219e-01</td>\n",
              "      <td>0.118540</td>\n",
              "      <td>0.072682</td>\n",
              "      <td>0.401284</td>\n",
              "      <td>4.436399e-02</td>\n",
              "      <td>3.666615e-04</td>\n",
              "      <td>2.596706e-08</td>\n",
              "      <td>0.004904</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.004918</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>3.151547e-03</td>\n",
              "      <td>1.810462e-03</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>1.487672e-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3430 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 3001      3002  ...      2999          3000\n",
              "topic_0  7.655325e-02  0.000187  ...  0.011725  1.808449e-05\n",
              "topic_1  5.757245e-02  0.000058  ...  0.000511  2.141559e-04\n",
              "topic_2  8.684420e-08  0.031961  ...  0.000006  7.136307e-13\n",
              "topic_3  9.985089e-03  0.000003  ...  0.000952  2.206358e-05\n",
              "topic_4  4.206443e-01  0.023032  ...  0.000090  1.487672e-03\n",
              "\n",
              "[5 rows x 3430 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQzfzyVpkN2O"
      },
      "source": [
        "А чтобы получить p(c|d), запустите такой код:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lnkIfuCkN2O"
      },
      "source": [
        "p_cd_test = model.transform(batch_vectorizer=batch_vectorizer, predict_class_id='@labels_class') # !FIX_ME: здесь на самом деле д.б. batch_vectorizer=batch_vectorizer_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q2_UvhRkN2R"
      },
      "source": [
        "Таким образом, Вы получили предсказания модели в pandas.DataFrame. Теперь Вы можете оценить степень качества предсказаний построенной Вами модели любым способом, который Вам необходим."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJKrujVVkN2R"
      },
      "source": [
        "### 5. Извлечение $\\Phi$ и $\\Theta$, сохранение и загрузка модели, фильтрация словарей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "VxtMroARkN2S"
      },
      "source": [
        "Предположим, что у Вас есть данные, Вы обучили на них модель. Настроили все регуляризаторы, посмотрели на метрики качества. Однако набор метрик качества оказался недостаточным, и Вам требуется посчитать какие-то свои величины, основывающиеся на матрицах $\\Phi$ и $\\Theta$. В этом случае Вы можете извлечь эти матрицы наружу следующим кодом:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EORL1lwZkN2S"
      },
      "source": [
        "phi = model.get_phi()\n",
        "theta = model.get_theta()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "6IYeU0E3kN2V"
      },
      "source": [
        "Обязательно учтите, что для извлечения $\\Theta$ флаг cache_theta должен быть равен True. Извлечение матриц можно производить не только целиком (что произойдёт в коде выше), но и по темам (а для $\\Phi$ - еще и по модальностям).\n",
        "\n",
        "Оба метода возвращают pandas.DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm7pBrKj9Gbh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "22559ba8-ddf2-4130-efcc-0b1bee20ac55"
      },
      "source": [
        "phi.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic_0</th>\n",
              "      <th>topic_1</th>\n",
              "      <th>topic_2</th>\n",
              "      <th>topic_3</th>\n",
              "      <th>topic_4</th>\n",
              "      <th>topic_5</th>\n",
              "      <th>topic_6</th>\n",
              "      <th>topic_7</th>\n",
              "      <th>topic_8</th>\n",
              "      <th>topic_9</th>\n",
              "      <th>topic_10</th>\n",
              "      <th>topic_11</th>\n",
              "      <th>topic_12</th>\n",
              "      <th>topic_13</th>\n",
              "      <th>topic_14</th>\n",
              "      <th>topic_15</th>\n",
              "      <th>topic_16</th>\n",
              "      <th>topic_17</th>\n",
              "      <th>topic_18</th>\n",
              "      <th>topic_19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sawyer</th>\n",
              "      <td>1.580580e-15</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.074622e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.453917e-14</td>\n",
              "      <td>1.168839e-14</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.249261e-14</td>\n",
              "      <td>1.168317e-14</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.412881e-14</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.570276e-16</td>\n",
              "      <td>1.945531e-14</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.030648e-14</td>\n",
              "      <td>3.673996e-14</td>\n",
              "      <td>3.825178e-04</td>\n",
              "      <td>4.766952e-11</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>harts</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.871723e-10</td>\n",
              "      <td>3.580617e-13</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.949688e-12</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.057922e-15</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.260138e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.473501e-04</td>\n",
              "      <td>2.368419e-12</td>\n",
              "      <td>3.597647e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amdt</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.712139e-12</td>\n",
              "      <td>4.529132e-13</td>\n",
              "      <td>9.442705e-13</td>\n",
              "      <td>4.351712e-14</td>\n",
              "      <td>1.404769e-12</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.858336e-13</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.419933e-12</td>\n",
              "      <td>3.213700e-12</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.582513e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zimbabwe</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.230303e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.516547e-16</td>\n",
              "      <td>2.234705e-15</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.380370e-15</td>\n",
              "      <td>7.197055e-14</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.113759e-16</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.725432e-15</td>\n",
              "      <td>2.542510e-12</td>\n",
              "      <td>4.748122e-04</td>\n",
              "      <td>4.095564e-15</td>\n",
              "      <td>3.960122e-11</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lindauer</th>\n",
              "      <td>3.553034e-14</td>\n",
              "      <td>1.410405e-12</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.229725e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.303838e-10</td>\n",
              "      <td>1.159777e-12</td>\n",
              "      <td>2.668111e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.273816e-04</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.913797e-12</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.787916e-16</td>\n",
              "      <td>2.068892e-06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.415614e-14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               topic_0       topic_1  ...      topic_18      topic_19\n",
              "sawyer    1.580580e-15  0.000000e+00  ...  4.766952e-11  0.000000e+00\n",
              "harts     0.000000e+00  0.000000e+00  ...  2.368419e-12  3.597647e-12\n",
              "amdt      0.000000e+00  0.000000e+00  ...  0.000000e+00  6.582513e-04\n",
              "zimbabwe  0.000000e+00  1.230303e-07  ...  3.960122e-11  0.000000e+00\n",
              "lindauer  3.553034e-14  1.410405e-12  ...  0.000000e+00  2.415614e-14\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFISZAyf9JBs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "cc2408f9-b1dd-4bc9-b582-147a941c0b1a"
      },
      "source": [
        "theta.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3001</th>\n",
              "      <th>3002</th>\n",
              "      <th>3003</th>\n",
              "      <th>3004</th>\n",
              "      <th>3005</th>\n",
              "      <th>3006</th>\n",
              "      <th>3007</th>\n",
              "      <th>3008</th>\n",
              "      <th>3009</th>\n",
              "      <th>3010</th>\n",
              "      <th>3011</th>\n",
              "      <th>3012</th>\n",
              "      <th>3013</th>\n",
              "      <th>3014</th>\n",
              "      <th>3015</th>\n",
              "      <th>3016</th>\n",
              "      <th>3017</th>\n",
              "      <th>3018</th>\n",
              "      <th>3019</th>\n",
              "      <th>3020</th>\n",
              "      <th>3021</th>\n",
              "      <th>3022</th>\n",
              "      <th>3023</th>\n",
              "      <th>3024</th>\n",
              "      <th>3025</th>\n",
              "      <th>3026</th>\n",
              "      <th>3027</th>\n",
              "      <th>3028</th>\n",
              "      <th>3029</th>\n",
              "      <th>3030</th>\n",
              "      <th>3031</th>\n",
              "      <th>3032</th>\n",
              "      <th>3033</th>\n",
              "      <th>3034</th>\n",
              "      <th>3035</th>\n",
              "      <th>3036</th>\n",
              "      <th>3037</th>\n",
              "      <th>3038</th>\n",
              "      <th>3039</th>\n",
              "      <th>3040</th>\n",
              "      <th>...</th>\n",
              "      <th>2961</th>\n",
              "      <th>2962</th>\n",
              "      <th>2963</th>\n",
              "      <th>2964</th>\n",
              "      <th>2965</th>\n",
              "      <th>2966</th>\n",
              "      <th>2967</th>\n",
              "      <th>2968</th>\n",
              "      <th>2969</th>\n",
              "      <th>2970</th>\n",
              "      <th>2971</th>\n",
              "      <th>2972</th>\n",
              "      <th>2973</th>\n",
              "      <th>2974</th>\n",
              "      <th>2975</th>\n",
              "      <th>2976</th>\n",
              "      <th>2977</th>\n",
              "      <th>2978</th>\n",
              "      <th>2979</th>\n",
              "      <th>2980</th>\n",
              "      <th>2981</th>\n",
              "      <th>2982</th>\n",
              "      <th>2983</th>\n",
              "      <th>2984</th>\n",
              "      <th>2985</th>\n",
              "      <th>2986</th>\n",
              "      <th>2987</th>\n",
              "      <th>2988</th>\n",
              "      <th>2989</th>\n",
              "      <th>2990</th>\n",
              "      <th>2991</th>\n",
              "      <th>2992</th>\n",
              "      <th>2993</th>\n",
              "      <th>2994</th>\n",
              "      <th>2995</th>\n",
              "      <th>2996</th>\n",
              "      <th>2997</th>\n",
              "      <th>2998</th>\n",
              "      <th>2999</th>\n",
              "      <th>3000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>topic_0</th>\n",
              "      <td>7.087864e-02</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>1.019987e-02</td>\n",
              "      <td>0.173995</td>\n",
              "      <td>0.008276</td>\n",
              "      <td>4.702336e-07</td>\n",
              "      <td>0.044054</td>\n",
              "      <td>1.118001e-04</td>\n",
              "      <td>0.000832</td>\n",
              "      <td>0.002299</td>\n",
              "      <td>2.232762e-02</td>\n",
              "      <td>0.002389</td>\n",
              "      <td>4.575441e-04</td>\n",
              "      <td>4.884994e-03</td>\n",
              "      <td>3.407793e-05</td>\n",
              "      <td>5.288344e-04</td>\n",
              "      <td>0.018395</td>\n",
              "      <td>2.604860e-05</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>2.276880e-02</td>\n",
              "      <td>1.039020e-06</td>\n",
              "      <td>0.010464</td>\n",
              "      <td>0.011608</td>\n",
              "      <td>0.216781</td>\n",
              "      <td>6.152885e-02</td>\n",
              "      <td>1.252777e-03</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>1.392566e-05</td>\n",
              "      <td>0.000207</td>\n",
              "      <td>0.083618</td>\n",
              "      <td>8.572354e-02</td>\n",
              "      <td>1.388343e-02</td>\n",
              "      <td>2.095680e-06</td>\n",
              "      <td>7.041005e-04</td>\n",
              "      <td>0.001829</td>\n",
              "      <td>6.655575e-05</td>\n",
              "      <td>0.036892</td>\n",
              "      <td>2.730118e-04</td>\n",
              "      <td>0.003392</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008621</td>\n",
              "      <td>0.132581</td>\n",
              "      <td>3.038033e-01</td>\n",
              "      <td>0.004645</td>\n",
              "      <td>0.115369</td>\n",
              "      <td>0.003085</td>\n",
              "      <td>0.001127</td>\n",
              "      <td>2.380121e-03</td>\n",
              "      <td>8.655534e-08</td>\n",
              "      <td>0.009203</td>\n",
              "      <td>0.002818</td>\n",
              "      <td>1.721807e-06</td>\n",
              "      <td>5.451525e-05</td>\n",
              "      <td>0.387338</td>\n",
              "      <td>0.001914</td>\n",
              "      <td>3.377678e-06</td>\n",
              "      <td>1.517336e-02</td>\n",
              "      <td>9.810560e-04</td>\n",
              "      <td>0.090942</td>\n",
              "      <td>0.006051</td>\n",
              "      <td>0.001942</td>\n",
              "      <td>0.004335</td>\n",
              "      <td>7.978920e-03</td>\n",
              "      <td>1.987912e-03</td>\n",
              "      <td>2.844177e-02</td>\n",
              "      <td>9.110891e-03</td>\n",
              "      <td>0.005811</td>\n",
              "      <td>0.031453</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>4.259612e-02</td>\n",
              "      <td>1.436941e-04</td>\n",
              "      <td>6.215406e-06</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.023798</td>\n",
              "      <td>0.006381</td>\n",
              "      <td>7.190107e-02</td>\n",
              "      <td>3.113123e-04</td>\n",
              "      <td>0.017994</td>\n",
              "      <td>1.779143e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_1</th>\n",
              "      <td>5.432793e-02</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>3.958819e-05</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>2.066767e-08</td>\n",
              "      <td>0.011795</td>\n",
              "      <td>4.760951e-07</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>1.235943e-02</td>\n",
              "      <td>0.006745</td>\n",
              "      <td>4.980803e-02</td>\n",
              "      <td>4.795023e-02</td>\n",
              "      <td>1.134349e-02</td>\n",
              "      <td>7.581239e-02</td>\n",
              "      <td>0.007029</td>\n",
              "      <td>4.914259e-05</td>\n",
              "      <td>0.048806</td>\n",
              "      <td>3.691733e-04</td>\n",
              "      <td>6.994807e-02</td>\n",
              "      <td>0.689687</td>\n",
              "      <td>0.497428</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>6.763391e-06</td>\n",
              "      <td>1.570594e-02</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>4.460410e-05</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>1.119641e-02</td>\n",
              "      <td>1.211536e-02</td>\n",
              "      <td>1.684376e-04</td>\n",
              "      <td>1.092155e-04</td>\n",
              "      <td>0.003845</td>\n",
              "      <td>1.603009e-07</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>1.208748e-03</td>\n",
              "      <td>0.014525</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.004114</td>\n",
              "      <td>2.537086e-04</td>\n",
              "      <td>0.046546</td>\n",
              "      <td>0.012405</td>\n",
              "      <td>0.206888</td>\n",
              "      <td>0.360079</td>\n",
              "      <td>7.663108e-01</td>\n",
              "      <td>3.808901e-06</td>\n",
              "      <td>0.021103</td>\n",
              "      <td>0.009095</td>\n",
              "      <td>9.540734e-07</td>\n",
              "      <td>8.525954e-01</td>\n",
              "      <td>0.015405</td>\n",
              "      <td>0.007209</td>\n",
              "      <td>9.780619e-01</td>\n",
              "      <td>4.543854e-03</td>\n",
              "      <td>1.375811e-04</td>\n",
              "      <td>0.001177</td>\n",
              "      <td>0.041041</td>\n",
              "      <td>0.002937</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>1.875941e-01</td>\n",
              "      <td>1.069639e-01</td>\n",
              "      <td>2.231957e-04</td>\n",
              "      <td>2.263597e-01</td>\n",
              "      <td>0.182818</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>9.783685e-04</td>\n",
              "      <td>5.480257e-07</td>\n",
              "      <td>1.312355e-07</td>\n",
              "      <td>0.154562</td>\n",
              "      <td>0.006293</td>\n",
              "      <td>0.005249</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>3.090288e-02</td>\n",
              "      <td>1.524375e-01</td>\n",
              "      <td>0.000419</td>\n",
              "      <td>2.345795e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_2</th>\n",
              "      <td>6.634311e-08</td>\n",
              "      <td>0.032853</td>\n",
              "      <td>4.431528e-07</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>0.001381</td>\n",
              "      <td>6.130345e-01</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>1.503435e-12</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>2.536980e-07</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>2.143861e-08</td>\n",
              "      <td>4.175419e-10</td>\n",
              "      <td>2.753134e-10</td>\n",
              "      <td>7.769298e-11</td>\n",
              "      <td>0.219795</td>\n",
              "      <td>2.346799e-09</td>\n",
              "      <td>0.014947</td>\n",
              "      <td>4.169919e-07</td>\n",
              "      <td>4.580494e-07</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000730</td>\n",
              "      <td>3.521197e-07</td>\n",
              "      <td>8.849311e-09</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>1.039433e-09</td>\n",
              "      <td>0.324380</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>3.007991e-08</td>\n",
              "      <td>5.102265e-09</td>\n",
              "      <td>8.434267e-08</td>\n",
              "      <td>5.820415e-08</td>\n",
              "      <td>0.025576</td>\n",
              "      <td>3.890514e-12</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>3.123276e-08</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>...</td>\n",
              "      <td>0.414984</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>4.736844e-11</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.001860</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>5.788990e-08</td>\n",
              "      <td>4.838091e-03</td>\n",
              "      <td>0.000717</td>\n",
              "      <td>0.008528</td>\n",
              "      <td>7.332778e-01</td>\n",
              "      <td>9.207286e-09</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>1.115635e-10</td>\n",
              "      <td>7.449190e-07</td>\n",
              "      <td>1.170146e-09</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.368779</td>\n",
              "      <td>2.569950e-07</td>\n",
              "      <td>1.788534e-07</td>\n",
              "      <td>9.206292e-08</td>\n",
              "      <td>9.060754e-10</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.011180</td>\n",
              "      <td>0.003377</td>\n",
              "      <td>3.355027e-07</td>\n",
              "      <td>4.714651e-02</td>\n",
              "      <td>1.923964e-02</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.450995</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>0.602991</td>\n",
              "      <td>2.439416e-09</td>\n",
              "      <td>1.975270e-07</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>9.678814e-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_3</th>\n",
              "      <td>9.756221e-03</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>1.319543e-03</td>\n",
              "      <td>0.072878</td>\n",
              "      <td>0.013532</td>\n",
              "      <td>1.619733e-04</td>\n",
              "      <td>0.109941</td>\n",
              "      <td>1.226580e-01</td>\n",
              "      <td>0.060136</td>\n",
              "      <td>0.002527</td>\n",
              "      <td>1.502048e-03</td>\n",
              "      <td>0.004367</td>\n",
              "      <td>1.693345e-02</td>\n",
              "      <td>5.986773e-04</td>\n",
              "      <td>1.594425e-03</td>\n",
              "      <td>2.131003e-03</td>\n",
              "      <td>0.005438</td>\n",
              "      <td>1.066288e-04</td>\n",
              "      <td>0.175338</td>\n",
              "      <td>7.151598e-01</td>\n",
              "      <td>1.778246e-04</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.043368</td>\n",
              "      <td>0.040722</td>\n",
              "      <td>1.808591e-01</td>\n",
              "      <td>2.261724e-05</td>\n",
              "      <td>0.222205</td>\n",
              "      <td>2.910747e-06</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.001315</td>\n",
              "      <td>2.130395e-03</td>\n",
              "      <td>1.754035e-02</td>\n",
              "      <td>1.815219e-05</td>\n",
              "      <td>2.093627e-03</td>\n",
              "      <td>0.004303</td>\n",
              "      <td>3.180600e-01</td>\n",
              "      <td>0.596139</td>\n",
              "      <td>9.503701e-04</td>\n",
              "      <td>0.052298</td>\n",
              "      <td>0.001879</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>3.028514e-03</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.008001</td>\n",
              "      <td>0.005978</td>\n",
              "      <td>0.001788</td>\n",
              "      <td>7.219035e-05</td>\n",
              "      <td>1.970071e-02</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000424</td>\n",
              "      <td>6.122718e-06</td>\n",
              "      <td>3.693978e-05</td>\n",
              "      <td>0.006054</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>9.926159e-08</td>\n",
              "      <td>5.387390e-02</td>\n",
              "      <td>4.264609e-02</td>\n",
              "      <td>0.373050</td>\n",
              "      <td>0.001841</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.002328</td>\n",
              "      <td>1.398437e-02</td>\n",
              "      <td>4.751192e-02</td>\n",
              "      <td>4.622108e-02</td>\n",
              "      <td>8.434097e-02</td>\n",
              "      <td>0.008532</td>\n",
              "      <td>0.109900</td>\n",
              "      <td>0.001671</td>\n",
              "      <td>1.919381e-04</td>\n",
              "      <td>1.133071e-03</td>\n",
              "      <td>2.129721e-09</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000624</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>7.435334e-05</td>\n",
              "      <td>5.025494e-04</td>\n",
              "      <td>0.001009</td>\n",
              "      <td>2.981438e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_4</th>\n",
              "      <td>4.478861e-01</td>\n",
              "      <td>0.023251</td>\n",
              "      <td>8.394602e-02</td>\n",
              "      <td>0.001612</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>1.348207e-07</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>1.192210e-06</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.001571</td>\n",
              "      <td>3.987674e-02</td>\n",
              "      <td>0.008463</td>\n",
              "      <td>8.182053e-03</td>\n",
              "      <td>1.137103e-01</td>\n",
              "      <td>3.205889e-05</td>\n",
              "      <td>1.165384e-03</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>4.846037e-06</td>\n",
              "      <td>0.012639</td>\n",
              "      <td>6.349224e-03</td>\n",
              "      <td>1.450252e-03</td>\n",
              "      <td>0.017372</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000374</td>\n",
              "      <td>3.529313e-03</td>\n",
              "      <td>3.901662e-03</td>\n",
              "      <td>0.004515</td>\n",
              "      <td>3.404806e-06</td>\n",
              "      <td>0.000428</td>\n",
              "      <td>0.007746</td>\n",
              "      <td>2.386326e-02</td>\n",
              "      <td>1.259147e-02</td>\n",
              "      <td>1.291956e-04</td>\n",
              "      <td>2.875577e-03</td>\n",
              "      <td>0.104030</td>\n",
              "      <td>2.165060e-03</td>\n",
              "      <td>0.006190</td>\n",
              "      <td>7.050030e-05</td>\n",
              "      <td>0.085364</td>\n",
              "      <td>0.002986</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007054</td>\n",
              "      <td>0.008977</td>\n",
              "      <td>3.650552e-03</td>\n",
              "      <td>0.001983</td>\n",
              "      <td>0.261314</td>\n",
              "      <td>0.007002</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>4.512277e-03</td>\n",
              "      <td>2.170674e-05</td>\n",
              "      <td>0.062225</td>\n",
              "      <td>0.050942</td>\n",
              "      <td>3.455639e-06</td>\n",
              "      <td>1.904870e-02</td>\n",
              "      <td>0.473871</td>\n",
              "      <td>0.015739</td>\n",
              "      <td>2.943306e-03</td>\n",
              "      <td>1.290257e-02</td>\n",
              "      <td>3.102232e-03</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.304178</td>\n",
              "      <td>0.001531</td>\n",
              "      <td>0.000921</td>\n",
              "      <td>8.760727e-03</td>\n",
              "      <td>4.032418e-02</td>\n",
              "      <td>1.125263e-01</td>\n",
              "      <td>1.145813e-01</td>\n",
              "      <td>0.124067</td>\n",
              "      <td>0.070877</td>\n",
              "      <td>0.392168</td>\n",
              "      <td>4.087957e-02</td>\n",
              "      <td>3.885822e-04</td>\n",
              "      <td>3.057414e-08</td>\n",
              "      <td>0.006166</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.005402</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>2.895299e-03</td>\n",
              "      <td>1.473001e-03</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>1.736164e-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3430 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 3001      3002  ...      2999          3000\n",
              "topic_0  7.087864e-02  0.000257  ...  0.017994  1.779143e-05\n",
              "topic_1  5.432793e-02  0.000056  ...  0.000419  2.345795e-04\n",
              "topic_2  6.634311e-08  0.032853  ...  0.000006  9.678814e-13\n",
              "topic_3  9.756221e-03  0.000002  ...  0.001009  2.981438e-05\n",
              "topic_4  4.478861e-01  0.023251  ...  0.000101  1.736164e-03\n",
              "\n",
              "[5 rows x 3430 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEobS0orkN2W"
      },
      "source": [
        "Теперь перейдём к вопросу сохранения модели на диск для дальнейшего использования.\n",
        "\n",
        "Здесь важно понимать, что модель состоит из двух матриц - $\\Phi$ (она же $p_{wt}$) и $n_{wt}$. Для того, чтобы её можно было загрузить обратно и продолжить обучение с того же места, необходимо сохранять и загружать обе матрицы. Текущая версия библиотеки умеет сохранять только одну матрицу, поэтому придётся сделать два вызова save:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okF-7lX8kN2W"
      },
      "source": [
        "model.save(filename='saved_p_wt', model_name='p_wt')\n",
        "model.save(filename='saved_n_wt', model_name='n_wt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5MmdhblkN2Y"
      },
      "source": [
        "Модель будет сохранена в бинарном виде, её можно использовать в дальнейшем, достаточно загрузить эти файлы обратно вызовами:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm3UtFJbkN2Y"
      },
      "source": [
        "model.load(filename='saved_p_wt', model_name='p_wt')\n",
        "model.load(filename='saved_n_wt', model_name='n_wt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwGE59FGkN2Z"
      },
      "source": [
        "Надо понимать, что модель после загрузки содержит только матрицы $\\Phi$ и $n_{wt}$ и сопутствующую информацию (число и имена тем, имена (но не веса!) модальностей и некоторые другие параметры). Поэтому от Вас потребуется некоторые усилия, чтобы вернуть модели все метрики, регуляризаторы, веса модальностей и важные для Вас параметры, вроде cache_theta. Если Вам это всё, конечно, нужно. Делается это в тех случаях, когда обучение модели с нуля занимает очень много времени и быстрее прописать заново параметры."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efespf4DkN2a"
      },
      "source": [
        "Последнее, чего мы коснёмся в этом разделе - словари. А именно - их возможности по самофильтрации. Вспомним вид словаря, выгруженного в текстовом виде. Это были строки, каждая соответствует одному слову, и в ней 5 значений: само слово (строка), его модальность (строка), его value (число), и две пока ещё неизвестных величины token_tf и token_df (тоже числа). Раскроем, наконец, их смысл, который довольно прост: это, соответственно, частота слова в коллекции (нормировкой это величины получается исходное value) и подокументная частота (т. е. в скольки документах коллекции слово встретилось хотя бы раз). Эти величины, как и value, генерируются библиотекой при сборе словаря. Отличие от value в том, что они не используются в регуляризаторах и метриках. Поэтому их менять бессмысленно и не следует.\n",
        "\n",
        "Они нужны для того, чтобы фильтровать словарь коллекции. Наверняка Вам не нужны слишком редкие, или же слишком частые слова. Ну или хочется уменьшить словарь, чтобы модель влезала в память. В обоих случаях решение одно, и оно очень простое - Dictionary.filter(). Посмотрите, какие у этого метода есть параметры здесь http://bigartm.readthedocs.org/en/master/api_references/python_interface/dictionary.html. Итак, будем фильтровать модальность обычных слов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBOevT6DkN2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "390271db-67a2-4a83-a96e-4a44619b2d43"
      },
      "source": [
        "dictionary.filter(min_tf=10, max_tf=2000, min_df_rate=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "artm.Dictionary(name=1ec8d593-6f5f-448a-9377-b4a8ebbaf497, num_entries=2266)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtBcZyzCkN2c"
      },
      "source": [
        "Поясню: если суффикса \\_rate нет, то используется абсолютная величина, если есть - нормированная (т. е. от 0 до 1).\n",
        "\n",
        "У этого вызова есть одна особенность - он перезаписывает старый словарь новым. Поэтому, если не хотите потерять полноценный нефильтрованный словарь, сохраните его сперва на диск, а потом уже с оставшейся в памяти копией выполняйте операции фильтрации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O35apTKAmpP9"
      },
      "source": [
        "### Факультативно: Модельный эксперимент с использованием BigARTM Python API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKE9mFzlmpP-"
      },
      "source": [
        "Credits: **Мурат Апишев** (great-mel@yandex.ru)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugbWAOklmpP_"
      },
      "source": [
        "#### Описание:\n",
        "Построим две тематические модели коллекции текстовых документов, ARTM и PLSA, сравним качество полученных моделей.\n",
        "\n",
        "#### Функционалы качества:\n",
        "Важным функционалом является перплексия коллекции. Тем не менее это далеко не единственная величина, характеризующая качество обучения. В BigARTM реализованы следующие функционалы:\n",
        "\n",
        "- разреженность матрицы $\\Phi$ (слова-темы);\n",
        "- разреженность матрицы $\\Theta$ (темы-документы);\n",
        "- характеристики ядер тем (чистота, контрастность, размер);\n",
        "- перплексия;\n",
        "- веса тем;\n",
        "- доля фоновых слов;\n",
        "- когерентность топ-слов и слов из ядер тем.\n",
        "\n",
        "Мы будем использовать первые четыре. Более сильные разреженности матриц и более высокие средние значения чистоты и контрастности способствуют большей интерпретируемости модели.\n",
        "\n",
        "#### Цель эксперимента:\n",
        "Попробуем обучить модель ARTM таким образом, чтобы, в сравнении с PLSA, улучшить значения разреженностей и ядровых характеристик и не сильно ухудшить перплексию.\n",
        "\n",
        "Основным инструментом для корректирования процесса обучения являются регуляризаторы. Список имеющихся в BigARTM регуляризаторов:\n",
        "\n",
        "- разреживание матрицы $\\Phi$ (+ частичное обучение);\n",
        "- разреживание матрицы $\\Theta$ (+ частичное обучение);\n",
        "- декоррелирование тем в матрице $\\Phi$;\n",
        "- принудительное разреживание $\\Phi$;\n",
        "- балансирование классов (Label Regularization);\n",
        "- повышение когерентности.\n",
        "\n",
        "В этом эксперименте для обучения ARTM воспользуемся первыми тремя регуляризаторами. ARTM без регуляризации соответствует PLSA.\n",
        "\n",
        "#### Коллекция:\n",
        "Воспользуемся небольшой коллекцией 'kos', доступной в репозитории UCI https://archive.ics.uci.edu/ml/machine-learning-databases/bag-of-words/. Параметры коллекции следующие:\n",
        "\n",
        "- 3430 документов;\n",
        "- 6906 слов в словаре;\n",
        "- 467714 ненулевых счётчиков в \"мешке слов\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jkEWgSZmpQA"
      },
      "source": [
        "Для начала подключим все необходимые модули:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKtEK8uGmpQA"
      },
      "source": [
        "%matplotlib inline\n",
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import artm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7g9_z_ompQD"
      },
      "source": [
        "Далее необходимо подготовить входные данные.\n",
        "\n",
        "Создадим объект BatchVectorizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaIAEEZ0mpQE"
      },
      "source": [
        "batch_vectorizer = None\n",
        "if len(glob.glob(os.path.join('kos', '*.batch'))) < 1:\n",
        "    batch_vectorizer = artm.BatchVectorizer(data_path='', data_format='bow_uci', collection_name='kos', target_folder='kos')\n",
        "else:\n",
        "    batch_vectorizer = artm.BatchVectorizer(data_path='kos', data_format='batches')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_Zo5cPnmpQH"
      },
      "source": [
        "dictionary = artm.Dictionary()\n",
        "\n",
        "model_plsa = artm.ARTM(topic_names=['topic_{}'.format(i) for i in range(15)],\n",
        "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
        "                                                    # use_unigram_document_model=False,\n",
        "                                                    dictionary=dictionary)],\n",
        "                       cache_theta=True)\n",
        "\n",
        "model_artm = artm.ARTM(topic_names=['topic_{}'.format(i) for i in range(15)],\n",
        "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
        "                                                    # use_unigram_document_model=False,\n",
        "                                                    dictionary=dictionary)],\n",
        "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.15)],\n",
        "                       cache_theta=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCWf0sVkmpQJ"
      },
      "source": [
        "Следующий шаг — инициализация моделей. Сделаем это по словарю."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oNQX0w9mpQJ"
      },
      "source": [
        "if not os.path.isfile('kos/dictionary.dict'):\n",
        "    dictionary.gather(data_path=batch_vectorizer.data_path)\n",
        "    dictionary.save(dictionary_path='kos/dictionary.dict')\n",
        "\n",
        "dictionary.load(dictionary_path='kos/dictionary.dict')\n",
        "dictionary.load(dictionary_path='kos/dictionary.dict')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zygMjDPxmpQM"
      },
      "source": [
        "Затем словари можно использовать, чтобы инициализировать модель:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkURJUlZmpQM"
      },
      "source": [
        "model_plsa.initialize(dictionary=dictionary)\n",
        "model_artm.initialize(dictionary=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3SuHFOhmpQO"
      },
      "source": [
        "Как уже было сказано, ARTM предоставляет возможность использовать все функционалы качества, имеющиеся в BigARTM. Если функционал подключен к модели, то модель будет сохранять все его значения, полученные на момент каждого обновления матрицы $\\Phi$. Добавим функционалы качества, нужные для нашего эксперимента, которые отсутствовали в конструкторах:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMfnvax7mpQP"
      },
      "source": [
        "model_plsa.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
        "model_plsa.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
        "model_plsa.scores.add(artm.TopicKernelScore(name='TopicKernelScore', probability_mass_threshold=0.3))\n",
        "\n",
        "model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
        "model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
        "model_artm.scores.add(artm.TopicKernelScore(name='TopicKernelScore', probability_mass_threshold=0.3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e3fDcI3mpQR"
      },
      "source": [
        "Аналогично поступим с регуляризаторами для model_artm (зададим им стартовые коэффициенты регуляризации, которые можно будет позже изменить при необходимости):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgoxwRB4mpQS"
      },
      "source": [
        "model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1))\n",
        "model_artm.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=1.5e+5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcnMC0TAmpQU"
      },
      "source": [
        "Теперь попробуем обучить модели в оффлайн-режиме (т. е. обновляя Фи раз за проход по коллекции). Инициируем пятнадцать проходов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKCfxJ1BmpQU"
      },
      "source": [
        "model_plsa.num_document_passes = 1\n",
        "model_artm.num_document_passes = 1\n",
        "\n",
        "model_plsa.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)\n",
        "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfF5Hm8fmpQW"
      },
      "source": [
        "Проверим результаты первой итерации обучения, сравнив финальные значения функционалов, а также графики перплексии (опишем печать в виде функции для возможности повторного использования):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6CbuLTQmpQX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "d58aa12c-66b4-414e-b37d-f5cb15c89eee"
      },
      "source": [
        "def print_measures(model_plsa, model_artm):\n",
        "    print('Sparsity Phi: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
        "        model_plsa.score_tracker['SparsityPhiScore'].last_value,\n",
        "        model_artm.score_tracker['SparsityPhiScore'].last_value))\n",
        "\n",
        "    print('Sparsity Theta: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
        "        model_plsa.score_tracker['SparsityThetaScore'].last_value,\n",
        "        model_artm.score_tracker['SparsityThetaScore'].last_value))\n",
        "\n",
        "    print('Kernel contrast: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
        "        model_plsa.score_tracker['TopicKernelScore'].last_average_contrast,\n",
        "        model_artm.score_tracker['TopicKernelScore'].last_average_contrast))\n",
        "\n",
        "    print('Kernel purity: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
        "        model_plsa.score_tracker['TopicKernelScore'].last_average_purity,\n",
        "        model_artm.score_tracker['TopicKernelScore'].last_average_purity))\n",
        "\n",
        "    print('Perplexity: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
        "        model_plsa.score_tracker['PerplexityScore'].last_value,\n",
        "        model_artm.score_tracker['PerplexityScore'].last_value))\n",
        "\n",
        "    plt.plot(range(model_plsa.num_phi_updates), model_plsa.score_tracker['PerplexityScore'].value, 'b--',\n",
        "             range(model_artm.num_phi_updates), model_artm.score_tracker['PerplexityScore'].value, 'r--', linewidth=2)\n",
        "    plt.xlabel('Iterations count')\n",
        "    plt.ylabel('PLSA perp. (blue), ARTM perp. (red)')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \n",
        "print_measures(model_plsa, model_artm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity Phi: 0.000 (PLSA) vs. 0.469 (ARTM)\n",
            "Sparsity Theta: 0.000 (PLSA) vs. 0.001 (ARTM)\n",
            "Kernel contrast: 0.466 (PLSA) vs. 0.525 (ARTM)\n",
            "Kernel purity: 0.215 (PLSA) vs. 0.359 (ARTM)\n",
            "Perplexity: 2058.028 (PLSA) vs. 1950.715 (ARTM)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CUNxGzempQa"
      },
      "source": [
        "Видно, что улучшения разреженностей и ядровых характеристик есть, а ухудшение перплексии невелико. Попробуем увеличить по модулю значения коэффициентов регуляризации при регуляризаторах:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1u3vf49mpQa"
      },
      "source": [
        "model_artm.regularizers['SparsePhi'].tau = -0.2\n",
        "model_artm.regularizers['SparseTheta'].tau = -0.2\n",
        "model_artm.regularizers['DecorrelatorPhi'].tau = 2.5e+5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STgZ_xZnmpQc"
      },
      "source": [
        "Кроме того, подключим к каждой из моделей функционал TopTokensScore, который позволит взглянуть на самые вероятные слова в каждой теме:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obkhYWGbmpQc"
      },
      "source": [
        "model_plsa.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))\n",
        "model_artm.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhksy6jFmpQf"
      },
      "source": [
        "Продолжим обучение моделей, инициировав 25 проходов по коллекции, после чего снова посмотрим на значения функционалов качества:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPrGXZF6mpQf"
      },
      "source": [
        "model_plsa.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)\n",
        "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJGLQV7MmpQh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "87c8a700-9b53-433d-cc4f-2cf5dd639311"
      },
      "source": [
        "print_measures(model_plsa, model_artm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity Phi: 0.093 (PLSA) vs. 0.841 (ARTM)\n",
            "Sparsity Theta: 0.000 (PLSA) vs. 0.023 (ARTM)\n",
            "Kernel contrast: 0.640 (PLSA) vs. 0.740 (ARTM)\n",
            "Kernel purity: 0.674 (PLSA) vs. 0.822 (ARTM)\n",
            "Perplexity: 1619.034 (PLSA) vs. 1644.218 (ARTM)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL0oec14mpQj"
      },
      "source": [
        "Кроме того, для наглядности построим графики изменения разреженностей матриц по итерациям:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBNXoNsumpQk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "b28ec3dc-773b-4720-f356-448f058757b6"
      },
      "source": [
        "plt.plot(range(model_plsa.num_phi_updates), model_plsa.score_tracker['SparsityPhiScore'].value, 'b--',\n",
        "                 range(model_artm.num_phi_updates), model_artm.score_tracker['SparsityPhiScore'].value, 'r--', linewidth=2)\n",
        "plt.xlabel('Iterations count')\n",
        "plt.ylabel('PLSA Phi sp. (blue), ARTM Phi sp. (red)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(model_plsa.num_phi_updates), model_plsa.score_tracker['SparsityThetaScore'].value, 'b--',\n",
        "                 range(model_artm.num_phi_updates), model_artm.score_tracker['SparsityThetaScore'].value, 'r--', linewidth=2)\n",
        "plt.xlabel('Iterations count')\n",
        "plt.ylabel('PLSA Theta sp. (blue), ARTM Theta sp. (red)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4qVs6NmumpQn"
      },
      "source": [
        "Кажется, что достигнутых результатов достаточно. Регуляризация позволила добиться улучшения всех характеристик, ухудшив перплексию в пределах разумного. Взглянем на топ-слова слова моделей:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb0Gx1DdmpQn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "27934e3a-4c49-445c-c29d-6c053cd5dd5f"
      },
      "source": [
        "for topic_name in model_plsa.topic_names:\n",
        "    print(topic_name + ': ')\n",
        "    print(model_plsa.score_tracker['TopTokensScore'].last_tokens[topic_name])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic_0: \n",
            "['year', 'tax', 'jobs', 'america', 'president', 'issues']\n",
            "topic_1: \n",
            "['people', 'war', 'service', 'military', 'rights', 'vietnam']\n",
            "topic_2: \n",
            "['november', 'electoral', 'account', 'polls', 'governor', 'contact']\n",
            "topic_3: \n",
            "['republican', 'gop', 'senate', 'senator', 'south', 'conservative']\n",
            "topic_4: \n",
            "['people', 'time', 'country', 'speech', 'talking', 'read']\n",
            "topic_5: \n",
            "['dean', 'democratic', 'edwards', 'primary', 'kerry', 'clark']\n",
            "topic_6: \n",
            "['state', 'party', 'race', 'candidates', 'candidate', 'elections']\n",
            "topic_7: \n",
            "['administration', 'president', 'years', 'bill', 'white', 'cheney']\n",
            "topic_8: \n",
            "['campaign', 'national', 'media', 'local', 'late', 'union']\n",
            "topic_9: \n",
            "['house', 'million', 'money', 'republican', 'committee', 'delay']\n",
            "topic_10: \n",
            "['republicans', 'vote', 'senate', 'election', 'democrats', 'house']\n",
            "topic_11: \n",
            "['iraq', 'war', 'american', 'iraqi', 'military', 'intelligence']\n",
            "topic_12: \n",
            "['kerry', 'poll', 'percent', 'voters', 'polls', 'numbers']\n",
            "topic_13: \n",
            "['news', 'time', 'asked', 'political', 'washington', 'long']\n",
            "topic_14: \n",
            "['bush', 'general', 'bushs', 'kerry', 'oct', 'states']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVezGqbompQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "217b3f44-d619-40a2-bf3b-4554cd42dc00"
      },
      "source": [
        "for topic_name in model_artm.topic_names:\n",
        "    print(topic_name + ': ')\n",
        "    print(model_artm.score_tracker['TopTokensScore'].last_tokens[topic_name])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic_0: \n",
            "['party', 'political', 'issue', 'tax', 'america', 'issues']\n",
            "topic_1: \n",
            "['people', 'military', 'official', 'officials', 'service', 'public']\n",
            "topic_2: \n",
            "['electoral', 'governor', 'account', 'contact', 'ticket', 'experience']\n",
            "topic_3: \n",
            "['gop', 'convention', 'senator', 'debate', 'south', 'sen']\n",
            "topic_4: \n",
            "['country', 'speech', 'bad', 'read', 'end', 'talking']\n",
            "topic_5: \n",
            "['democratic', 'dean', 'john', 'edwards', 'primary', 'clark']\n",
            "topic_6: \n",
            "['percent', 'race', 'candidates', 'candidate', 'win', 'nader']\n",
            "topic_7: \n",
            "['administration', 'years', 'white', 'year', 'bill', 'jobs']\n",
            "topic_8: \n",
            "['campaign', 'national', 'media', 'press', 'local', 'ads']\n",
            "topic_9: \n",
            "['house', 'republican', 'million', 'money', 'elections', 'district']\n",
            "topic_10: \n",
            "['november', 'poll', 'senate', 'republicans', 'vote', 'election']\n",
            "topic_11: \n",
            "['iraq', 'war', 'american', 'iraqi', 'security', 'united']\n",
            "topic_12: \n",
            "['bush', 'kerry', 'general', 'president', 'voters', 'bushs']\n",
            "topic_13: \n",
            "['time', 'news', 'long', 'asked', 'washington', 'political']\n",
            "topic_14: \n",
            "['state', 'states', 'people', 'oct', 'fact', 'ohio']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "JPyCLez8mpQr"
      },
      "source": [
        "Видно, что темы примерно одинаково интерпретируемы, но в модели ARTM они существенно разнообразнее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx_tMnRXmpQs"
      },
      "source": [
        "Извлечём матрицу $\\Phi$ в виде pandas.DataFrame и напечатаем её (в случае необходимости, можно извлекать части матрицы с помощью метода ARTM.get_phi()):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aNuHl0mmpQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d8a62f88-e8b2-4038-f377-18c5cfe42f03"
      },
      "source": [
        "print(model_artm.phi_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               topic_0   topic_1  topic_2  ...  topic_12  topic_13  topic_14\n",
            "sawyer        0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000\n",
            "harts         0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000\n",
            "amdt          0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000\n",
            "zimbabwe      0.000000  0.000285  0.00000  ...  0.000000  0.000000  0.000000\n",
            "lindauer      0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000\n",
            "...                ...       ...      ...  ...       ...       ...       ...\n",
            "history       0.003673  0.000757  0.00000  ...  0.000000  0.000000  0.000525\n",
            "figures       0.000046  0.000000  0.00000  ...  0.000000  0.000086  0.001609\n",
            "consistently  0.000000  0.000000  0.00000  ...  0.000202  0.000000  0.001057\n",
            "section       0.000000  0.000000  0.00997  ...  0.000000  0.000000  0.000000\n",
            "loan          0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000\n",
            "\n",
            "[6906 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxoPY2_8mpQu"
      },
      "source": [
        "Дополнительно извлечём $\\Theta$ в виде pandas.DataFrame и напечатаем её:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4trJNeaPmpQu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "b028b563-f2a5-48fc-fb2e-81a438cafe64"
      },
      "source": [
        "theta_matrix = model_artm.get_theta()\n",
        "print(theta_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              2001      2002      2003  ...      1998      1999      2000\n",
            "topic_0   0.073776  0.104943  0.042905  ...  0.097601  0.074183  0.014716\n",
            "topic_1   0.020828  0.038438  0.000000  ...  0.080923  0.031054  0.005184\n",
            "topic_2   0.017916  0.020015  0.032033  ...  0.007222  0.000000  0.000000\n",
            "topic_3   0.101466  0.012634  0.031944  ...  0.034290  0.018526  0.033572\n",
            "topic_4   0.043031  0.093771  0.061861  ...  0.030466  0.028672  0.047126\n",
            "topic_5   0.089614  0.308603  0.353586  ...  0.228804  0.368793  0.424608\n",
            "topic_6   0.094428  0.059448  0.066714  ...  0.081716  0.079300  0.107600\n",
            "topic_7   0.044239  0.027162  0.000000  ...  0.036864  0.033008  0.006729\n",
            "topic_8   0.131643  0.108485  0.126101  ...  0.114196  0.041101  0.059586\n",
            "topic_9   0.219474  0.017388  0.004687  ...  0.059266  0.005540  0.007309\n",
            "topic_10  0.037911  0.052984  0.054648  ...  0.055971  0.055681  0.047264\n",
            "topic_11  0.002883  0.005720  0.005455  ...  0.022400  0.011004  0.000000\n",
            "topic_12  0.034635  0.041271  0.160479  ...  0.042442  0.197913  0.162937\n",
            "topic_13  0.033249  0.018402  0.010357  ...  0.024499  0.007307  0.013284\n",
            "topic_14  0.054907  0.090734  0.049230  ...  0.083341  0.047918  0.070086\n",
            "\n",
            "[15 rows x 3430 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYKO2_mJHTAV"
      },
      "source": [
        "!mkdir kos_test\n",
        "!cp ./kos/aaaaad.batch ./kos_test/test_docs.batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XIuEwivmpQw"
      },
      "source": [
        "Можно использовать модель для определения векторов $\\theta_d$ для новых документов с помощью метода ARTM.transform():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YOAIZ2ytmpQw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "1b2457c0-34a3-45ed-c37e-9f69c1b8f084"
      },
      "source": [
        "test_batch_vectorizer = artm.BatchVectorizer(data_format='batches', data_path='kos_test', batches=['test_docs.batch'])\n",
        "test_theta_matrix = model_artm.transform(batch_vectorizer=test_batch_vectorizer)\n",
        "print(test_theta_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              3001      3002      3003  ...      3428      3429      3430\n",
            "topic_0   0.075921  0.036025  0.070347  ...  0.230674  0.183250  0.061460\n",
            "topic_1   0.095511  0.029142  0.034926  ...  0.050961  0.016203  0.070528\n",
            "topic_2   0.004073  0.048534  0.012111  ...  0.018511  0.000000  0.000000\n",
            "topic_3   0.057418  0.029879  0.122530  ...  0.057928  0.193814  0.129680\n",
            "topic_4   0.123294  0.046357  0.084458  ...  0.113776  0.041241  0.075501\n",
            "topic_5   0.025445  0.010652  0.024189  ...  0.019120  0.045632  0.048145\n",
            "topic_6   0.044675  0.017211  0.072166  ...  0.009487  0.090483  0.071808\n",
            "topic_7   0.061818  0.060667  0.021505  ...  0.109989  0.061353  0.053020\n",
            "topic_8   0.049570  0.048646  0.043328  ...  0.060510  0.041052  0.099531\n",
            "topic_9   0.070232  0.491968  0.013986  ...  0.063917  0.036156  0.020280\n",
            "topic_10  0.056565  0.023245  0.158611  ...  0.024147  0.031914  0.018237\n",
            "topic_11  0.158806  0.031703  0.028202  ...  0.051376  0.052091  0.119735\n",
            "topic_12  0.054115  0.027403  0.192328  ...  0.078734  0.097283  0.111705\n",
            "topic_13  0.055276  0.055656  0.025469  ...  0.091755  0.069910  0.080938\n",
            "topic_14  0.067281  0.042911  0.095845  ...  0.019116  0.039619  0.039434\n",
            "\n",
            "[15 rows x 430 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbdX-J1lmpQy"
      },
      "source": [
        "#### Выводы\n",
        "\n",
        "Задача построения тематической модели имеет бесконечно большое множество решений. Это даёт большую свободу действий, и регуляризаторы позволяют использовать её для получения результата, удовлетворяющего сразу нескольким требованиям (разреженность, интерпретируемость, удовлетворительное значение перплексии и т. п.).\n",
        "\n",
        "Приведённый выше пример является демонстрационным, можно пробовать более гибкие стратегии регуляризации для получения ещё более хорошего результата. По аналогичной схеме можно производить эксперименты с более крупными коллекциями."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K70tSf6UUbFD"
      },
      "source": [
        "### **VisARTM** - визуализатор для BigARTM\n",
        "\n",
        "https://github.com/bigartm/visartm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swpycwnPUQH2"
      },
      "source": [
        "![alt text](https://i.ibb.co/5W50kJt/Screenshot-2020-05-06-at-21-47-32.png)\n",
        "\n",
        "---\n",
        "http://www.machinelearning.ru/wiki/images/d/d8/Fedoriaka17bsc.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnnPaXVw8CEH"
      },
      "source": [
        "# clear work directory\n",
        "# !rm -rf /content/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDzLS2VlbP1b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}